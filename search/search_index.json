{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome","text":""},{"location":"#about-me","title":"About me","text":"<p>I am a senior principal engineer with 18 years of experience in \"figuring things out\" in technical support, IT, management, and software engineering roles at Milestone Systems, a leading global video management systems software vendor.</p> <p>After discovering the joy of using PowerShell in 2019, building MilestonePSTools, a commercial module for managing and automating Milestone XProtect software with PowerShell, connecting with members of the PowerShell &amp; DevOps communities, and a little arm-twisting, I delivered my first public session at the PowerShell + DevOps Global Summit in April of '24 titled \"Building Beautiful Documentation\".</p> <p>I can be found on Mastodon, Twitter, GitHub, and LinkIn as @joshooaj and I am always happy to make time for conferences, user groups, and members of the community who also made time for me.</p> <p>~ Josh</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2023/09/06/debugging-convertto-json/","title":"Debugging ConvertTo-Json","text":"<p>My co-worker, Jared, who regularly uses MilestonePSTools and builds tools with it brought me an interesting problem yesterday - an apparent compatibility issue between our SDK and the <code>ConvertTo-Json</code> cmdlet from the built-in Microsoft.PowerShell.Utility module. If you've ever struggled with the error \"ConvertTo-Json : An item with the same key has already been added.\", follow along as I share our debugging process until we finally discovered the root cause. While the details in this post involve the Milestone SDK and the MilestonePSTools module, the root cause and the process of finding it is relevant to anyone using .NET assemblies or 3rd party modules with PowerShell.</p>"},{"location":"blog/2023/09/06/debugging-convertto-json/#the-problem","title":"The problem","text":"<p>Jared built a fairly comprehensive tool to assist with migrating the configuration from one Milestone site to another. The tool gathers all the camera settings, groups, roles, views, and more, exports it mostly to JSON, and then allows for importing that collection of JSON files into another Milestone site for the purpose of consolidating many small systems into one or more larger systems.</p> <p>The tool is essentially complete, and Jared was updating to the latest release of MilestonePSTools and MipSdkRedist to verify that everything still worked with the most recent releases, and that's when he discovered it now failed with the error \"ConvertTo-Json : An item with the same key has already been added.\"</p>"},{"location":"blog/2023/09/06/debugging-convertto-json/#initial-questions","title":"Initial questions","text":"<p>The first thing Jared did was change nothing, other than to explicitly import an older version of MilestonePSTools where the problem was known not to exist. This is a great first step to answer the question \"is this a problem with the PowerShell module, or the state of the test VMS it is connected to?\"</p> <p>Surprisingly, after importing an older version of MilestonePSTools in a fresh new PowerShell terminal, the problem persisted. This was unexpected.</p> <p>After running <code>Get-Module</code> to list the imported modules, he could see that the desired version of MilestonePSTools was imported, but that the latest version of the SDK was being imported instead of the older version of the SDK. This is because MilestonePSTools only requires that MipSdkRedist is at least version x.y.z. By default, PowerShell imported the most recent version available.</p> <p>The next step was to explicitly import the older version of MipSdkRedist, and then import the older version of MilestonePSTools. At this point, he got the expected result - everything worked correctly.</p> <p>By this stage, Jared had narrowed the issue down to the latest release of MipSdkRedist since the known-good version of MilestonePSTools failed when using the latest MipSdkRedist release, and succeeded when using the older MipSdkRedist release. The last thing he did before reaching out to me was check to see whether the depth mattered, so he tried a depth of 1 and a depth of 100 and they both failed when using the latest MipSdkRedist module version.</p>"},{"location":"blog/2023/09/06/debugging-convertto-json/#is-this-a-bug","title":"Is this a bug?","text":"<p>It was at this point that Jared pinged me on Teams to let me know he might have found a bug in the MIP SDK. The MIP SDK is a dependency of MilestonePSTools that is maintained by a team in Denmark that we talk to regularly. But it isn't their responsibility to debug Microsoft's <code>ConvertTo-Json</code> cmdlet to figure out why it doesn't like some of the objects in our SDK, so we wanted to understand exactly why <code>ConvertTo-Json</code> was throwing this error.</p> <p>One of the first things we did was to search for similar reports online. Unfortunately we found several, and the comments weren't any better than the error message itself.</p> <p>The error \"An item with the same key has already been added\" is a well-known error to a .NET / C# developer and it happens when you try to add the same key to a dictionary twice. For example...</p> <pre><code>$dictionary = [collections.generic.dictionary[[string], [string]]]::new()\n$dictionary.Add('TestKey', 'TestValue')\n$dictionary.Add('TestKey', 'TestValue')\n</code></pre> <p>If you run that, you'll get the error <code>Exception calling \"Add\" with \"2\" argument(s): \"An item with the same key has already been added.\"</code>.</p> <p>But how exactly is <code>ConvertTo-Json</code> finding two properties with the same name on an object? When we use <code>Format-List</code> and <code>Get-Member</code> to inspect the properties of the offending object, each property is unique as expected. So is this a bug in the Milestone SDK, or is it a bug in <code>ConvertTo-Json</code>?</p>"},{"location":"blog/2023/09/06/debugging-convertto-json/#select-object","title":"Select-Object","text":"<p>We were working with a Role object, though later we would discover the issue applies to all configuration api objects. Anyway, on a whim I ran <code>$role | Select-Object * | ConvertTo-Json</code> and it worked normally. So there was definitely something hinky about the Role type.</p>"},{"location":"blog/2023/09/06/debugging-convertto-json/#expanding-the-error","title":"Expanding the error","text":"<p>Every error you see in PowerShell is added to the top of the automatic <code>$Error</code> variable which is an object of type <code>[System.Collections.ArrayList]</code> containing a collection of <code>[System.Management.Automation.ErrorRecord]</code> objects. You will often discover more detailed information by looking closer at these using <code>Format-List * -Force</code>, and by expanding the Exception and InnerException properties which can sometimes be nested several layers deep.</p> <p>Here's what I found...</p> <pre><code>$error[0] | Format-List -Force\n\n&lt;#\nException             : System.ArgumentException: An item with the same key has already been added.\n                           at System.ThrowHelper.ThrowArgumentException(ExceptionResource resource)\n                           at System.Collections.Generic.Dictionary`2.Insert(TKey key, TValue value, Boolean add)\n                           at Microsoft.PowerShell.Commands.ConvertToJsonCommand.ProcessCustomObject[T](Object o, Int32 depth)\n                           at Microsoft.PowerShell.Commands.ConvertToJsonCommand.ProcessValue(Object obj, Int32 depth)\n                           at Microsoft.PowerShell.Commands.ConvertToJsonCommand.EndProcessing()\n                           at System.Management.Automation.CommandProcessorBase.Complete()\nTargetObject          :\nCategoryInfo          : NotSpecified: (:) [ConvertTo-Json], ArgumentException\nFullyQualifiedErrorId : System.ArgumentException,Microsoft.PowerShell.Commands.ConvertToJsonCommand\nErrorDetails          :\nInvocationInfo        : System.Management.Automation.InvocationInfo\nScriptStackTrace      : at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1\nPipelineIterationInfo : {}\nPSMessageDetails      :\n#&gt;\n\n\n$error[0].Exception | Format-List -Force\n\n&lt;#\nMessage        : An item with the same key has already been added.\nParamName      :\nData           : {}\nInnerException :\nTargetSite     : Void ThrowArgumentException(System.ExceptionResource)\nStackTrace     :    at System.ThrowHelper.ThrowArgumentException(ExceptionResource resource)\n                    at System.Collections.Generic.Dictionary`2.Insert(TKey key, TValue value, Boolean add)\n                    at Microsoft.PowerShell.Commands.ConvertToJsonCommand.ProcessCustomObject[T](Object o, Int32 depth)\n                    at Microsoft.PowerShell.Commands.ConvertToJsonCommand.ProcessValue(Object obj, Int32 depth)\n                    at Microsoft.PowerShell.Commands.ConvertToJsonCommand.EndProcessing()\n                    at System.Management.Automation.CommandProcessorBase.Complete()\nHelpLink       :\nSource         : mscorlib\nHResult        : -2147024809\n#&gt;\n</code></pre> <p>Unfortunately I didn't learn much about why the exception was being thrown from digging into the error this time, but the stack trace would be useful in the next step.</p>"},{"location":"blog/2023/09/06/debugging-convertto-json/#time-to-decompile","title":"Time to decompile","text":"<p>I was running out of ideas and needed to see the implementation of <code>ConvertTo-Json</code> to understand how the cmdlet was finding two identical properties on my objects and what they were. By inspecting the error and referencing the stack trace, I knew that the <code>Microsoft.PowerShell.Commands.ConvertToJsonCommand.ProcessCustomObject[T](Object o, Int32 depth)</code> method is where a duplicate key was being added to a dictionary, so I checked the open-source version of PowerShell (PowerShell 7) on GitHub, but the implementation of <code>ConvertTo-Json</code> was too different from the PowerShell 5.1 version to be useful - it didn't have a ProcessCustomObject method.</p> <p>The source code for PowerShell 5.1 is not publicly available, so I had to resort to using a decompiler tool like DotPeek from JetBrains or JustDecompile from Telerik. Software and libraries written in C# or any other .NET language are compiled into CIL or \"common intermediate language\", or IL for short, which is governed by an open standard. Decompilers can look at a .EXE or .DLL file and interpret the IL, then produce a version of the what the original source code might look like. It's not perfect, and sometimes organizations use tools to obfuscate the compiled assemblies rendering them harder for a human to interpret, but most of the time you can get a good look at the source code and this was no exception.</p> <p>I won't share any screenshots or snippets of the source code for the <code>ConvertTo-Json</code> function as I don't want to risk any legal issues related to \"reverse engineering\" or releasing intellectual property. But here's what I found and how I found it...</p>"},{"location":"blog/2023/09/06/debugging-convertto-json/#finding-the-right-dll","title":"Finding the right DLL","text":"<p>To get a look at the source code, I needed to track down the assembly containing the definition for the <code>ConvertTo-Json</code> cmdlet. So I started with <code>Get-Command ConvertTo-Json | Format-List *</code> which returned the following. The highlighted line showing the path to the DLL is exactly what I needed.</p> <pre><code>HelpUri             : https://go.microsoft.com/fwlink/?LinkID=217032\nDLL                 : C:\\WINDOWS\\Microsoft.Net\\assembly\\GAC_MSIL\\Microsoft.PowerShell.Commands.Utility\\v4.0_3.0.0.0__31bf3856ad364e35\\Microsoft.PowerShell.Commands.Utility.dll\nVerb                : ConvertTo\nNoun                : Json\nHelpFile            : Microsoft.PowerShell.Commands.Utility.dll-Help.xml\nPSSnapIn            :\nVersion             : 3.1.0.0\nImplementingType    : Microsoft.PowerShell.Commands.ConvertToJsonCommand\nDefinition          :\n                      ConvertTo-Json [-InputObject] &lt;Object&gt; [-Depth &lt;int&gt;] [-Compress] [&lt;CommonParameters&gt;]\n\nDefaultParameterSet :\nOutputType          : {}\nOptions             : ReadOnly\nName                : ConvertTo-Json\nCommandType         : Cmdlet\nSource              : Microsoft.PowerShell.Utility\nVisibility          : Public\nModuleName          : Microsoft.PowerShell.Utility\nModule              : Microsoft.PowerShell.Utility\nRemotingCapability  : None\nParameters          : {[InputObject, System.Management.Automation.ParameterMetadata], [Depth, System.Management.Automation.ParameterMetadata], [Compress, System.Management.Automation.ParameterMetadata],\n                      [Verbose, System.Management.Automation.ParameterMetadata]...}\nParameterSets       : {[-InputObject] &lt;Object&gt; [-Depth &lt;int&gt;] [-Compress] [&lt;CommonParameters&gt;]}\n</code></pre>"},{"location":"blog/2023/09/06/debugging-convertto-json/#what-exactly-is-processcustomobject-doing","title":"What exactly is ProcessCustomObject doing?","text":"<p>Finally, using my favorite decompiler, I opened the DLL containing the <code>ConvertTo-Json</code> definition, and found the <code>ProcessCustomObject</code> method inside the class <code>Microsoft.PowerShell.Commands.ConvertToJsonCommand</code>. Inside the method, I could see that the fields and properties on the objects passed in were being discovered using <code>type.GetProperties(BindingFlags.Instance | BindingFlags.Public)</code>, so I wrote the same thing in PowerShell and retrieved the names and types of all the properties returned on a Role object. Check out the highlighted lines:</p> <pre><code>$type = (Get-VmsRole | Select-Object -First 1).GetType()\n$properties = $type.GetProperties(([system.reflection.bindingflags]::Instance -bor [system.reflection.bindingflags]::Public))\n$properties | Select-Object Name, PropertyType | Sort-Object Name\n\n&lt;#\nName                               PropertyType\n----                               ------------\nAllowMobileClientLogOn             System.Boolean\nAllowSmartClientLogOn              System.Boolean\nAllowWebClientLogOn                System.Boolean\nClaimFolder                        VideoOS.Platform.ConfigurationItems.ClaimFolder\nClientProfile                      System.String\nDescription                        System.String\nDisplayName                        System.String\nDualAuthorizationRequired          System.Boolean\nId                                 System.Guid\nId                                 System.String\nItemCategory                       System.String\nLastModified                       System.DateTime\nMakeUsersAnonymousDuringPTZSession System.Boolean\nMethods                            System.Collections.ObjectModel.Collection`1[System.String]\nName                               System.String\nParentItemPath                     System.String\nParentPath                         System.String\nPath                               System.String\nRoleClientLogOnTimeProfile         System.String\nRoleDefaultTimeProfile             System.String\nRoleType                           System.String\nRoleTypeValues                     System.Collections.Generic.Dictionary`2[System.String,System.String]\nServerId                           VideoOS.Platform.ServerId\nUserFolder                         VideoOS.Platform.ConfigurationItems.UserFolder\n#&gt;\n</code></pre> <p>So <code>ConvertTo-Json</code> is using reflection to inspect the objects to be serialized to JSON, and it's finding two different \"Id\" properties on the Role object - one of type <code>[string]</code> and one of type <code>[guid]</code>!</p> <p>Now that I knew which property was causing the problem, I could take a closer look at those specific properties...</p> <pre><code>$type = (Get-VmsRole | Select-Object -First 1).GetType()\n$properties = $type.GetProperties(([system.reflection.bindingflags]::Instance -bor [system.reflection.bindingflags]::Public)) | Where-Object Name -eq 'Id'\n$properties | Format-List * -Force\n\n&lt;#\nMemberType       : Property\nName             : Id\nDeclaringType    : VideoOS.Platform.ConfigurationItems.Role\nReflectedType    : VideoOS.Platform.ConfigurationItems.Role\nMetadataToken    : 385879854\nModule           : VideoOS.Platform.dll\nPropertyType     : System.String\nAttributes       : None\nCanRead          : True\nCanWrite         : False\nGetMethod        : System.String get_Id()\nSetMethod        :\nIsSpecialName    : False\nCustomAttributes : {[System.Diagnostics.CodeAnalysis.SuppressMessageAttribute(\"Microsoft.Naming\", \"CA1704:IdentifiersShouldBeSpelledCorrectly\")]}\n\nMemberType       : Property\nName             : Id\nDeclaringType    : VideoOS.Platform.ConfigurationItems.IConfigurationItem\nReflectedType    : VideoOS.Platform.ConfigurationItems.Role\nMetadataToken    : 385879365\nModule           : VideoOS.Platform.dll\nPropertyType     : System.Guid\nAttributes       : None\nCanRead          : True\nCanWrite         : False\nGetMethod        : System.Guid get_Id()\nSetMethod        :\nIsSpecialName    : False\nCustomAttributes : {}\n#&gt;\n</code></pre> <p>Looking at the <code>DeclaringType</code> property, I could see that the Id property of type <code>[string]</code> that I'm used to is declared on the Role type directly. However, the new <code>[guid]</code> Id property is defined on the IConfigurationItem type inherited from by the Role type. And indeed, looking at the source code for the SDK, that Id property was recently added for one reason or another and I'm now checking with the SDK team to understand why, and whether it is possible to safely change the implementation since it is a relatively new and apparently breaking change in rare circumstances.</p>"},{"location":"blog/2023/09/06/debugging-convertto-json/#what-next","title":"What next?","text":"<p>In our case, we can work around this duplicate Id property if needed by using <code>Select-Object</code> to filter for the properties we want, or even use <code>Select-Object *</code> which generates a new type on the fly with all the visible properties of the incoming object.</p> <p>I think the \"right way\" to resolve the issue is to make it so that the Id properties on both the IConfigurationItem and the various types that inherit from it are both of type <code>[string]</code> and then override the Id property on child types rather than declare another Id property which effectively \"hides\" the parent types version of the property except when using reflection.</p> <p>Reflection is the primary language tool in .NET for building serializers for converting objects to and from JSON, XML, and other formats, and using the override key word should hopefully make it so that the only Id property available to <code>ConvertTo-Json</code> and other serializers is the one on the objects where the property is overridden.</p>"},{"location":"blog/2024/03/21/new-pspushover-powershell-module/","title":"New PSPushover PowerShell Module","text":"<p>Back in 2021 I wrote a module called Poshover for sending push notifications with Pushover.net. This week I decided to use that module as a reference during my PowerShell + DevOps Summit workshop in a few weeks. I never liked the name, so I renamed it to PSPushover and set it up in a new repository.</p> <p></p> <p>The module itself is pretty fun - there's a lot of reasons you might want to use push notifications, especially if you maintain a home lab like I do. I use them to see when backup operations begin and end (or fail \ud83d\ude31), when my container host restarts, and when CrowdSec detects and blocks an external IP for suspicious or malicious activity.</p> <p>I think I enjoyed the process of setting up the repository more than the module itself. I plan to use it as an example of how you might automate the process of generating and updating documentation for your PowerShell modules, as well as how you can use MkDocs to generate a static website from your docs, and finally how you can automatically generate and host those docs with GitHub Pages. In this post though, I want to share some of the features of the repo and the tools used along the way. Check out the related links in the side bar to a bunch of the modules/utilities mentioned below.</p>"},{"location":"blog/2024/03/21/new-pspushover-powershell-module/#scaffolding","title":"Scaffolding","text":"<p>The scaffolding for the repo was done using Brandon Olin's Stucco module which has been my favorite way to start a new PowerShell module project for a while. It's not updated frequently and there are some issues I've run into in the past with some of the dependencies including RamblingCookieMonster's BuildHelpers and Brandon's PowerShellBuild module, but it gets me up and running fast and I'm pleased as punch with 90+% of Brandon's \"opinionated Plaster template for building high-quality PowerShell modules\".</p>"},{"location":"blog/2024/03/21/new-pspushover-powershell-module/#devcontainer-codespace","title":"DevContainer / Codespace","text":"<p>The Stucco plaster template includes a starter devcontainer, but since I want to use the devcontainer as a tool to build and serve an MkDocs site for local documentation previews, I changed the Dockerfile to use <code>squidfunk/mkdocs-material:latest</code> as a base image, and updated the file to install PowerShell 7 and setup a non-root user. And because I typically use a Windows laptop at home, I made some tweaks to <code>devcontainer.json</code> to handle some filesystem permission issues as well as to \"bootstrap\" the devcontainer on startup so that all the PowerShell and python dependencies are available.</p>"},{"location":"blog/2024/03/21/new-pspushover-powershell-module/#automated-versioning-with-nerdbankgitversioning","title":"Automated versioning with Nerdbank.GitVersioning","text":"<p>There are lots of ways to handle versioning. I've never looked into a strategy for automating the major/minor version numbers - that doesn't seem smart or easy to do while maintaining SemVer versioning. But I've done \"patch\" version updates in a few different ways in the past:</p> <ul> <li>Manually bumping the version before (or immediately after) releasing.<ul> <li>I don't like having to do a git commit to bump the version after every single release.</li> </ul> </li> <li>Using a version based on the time elapsed since the unix epoch.<ul> <li>This isn't bad but if you use days-since-epoch you can't easily release twice in a day if you need to. And the patch number can get pretty long.</li> </ul> </li> <li>Checking the latest version on PSGallery and incrementing it by one.<ul> <li>This is a great option. It puts a dependency on being able to reach PSGallery, but it has pretty good uptime and if you're publishing to the gallery anyway, your publish step will fail during an outage anyway.</li> </ul> </li> </ul> <p>My favorite method now is to use the Nerdbank.GitVersioning CLI tool, <code>nbgv</code>, with a <code>version.json</code> file at the root of the project to describe the version schema. The advantage here over the previous strategies I've used is that the module version can be easily connected to the associated git commit.</p> <p>Here's how it works with the PSPushover module right now:</p> <ol> <li>The <code>version.json</code> file provides the major/minor version numbers. The number in the module manifest is irrelevant as it will be updated as a part of the build.</li> <li>In <code>psakeFile.ps1</code>, I set the module version to use for the \"compiled\" module by running <code>nbgv get-version</code> and grabbing the <code>SimpleVersion</code> value.</li> <li>When it's time to bump the major or minor version, I'll update the <code>version.json</code> file. Until then, the versioning takes care of itself.</li> </ol>"},{"location":"blog/2024/03/21/new-pspushover-powershell-module/#automated-publishing-on-v-tags","title":"Automated publishing on v* tags","text":"<p>When a tag like \"v0.1.x\" is created on the main branch, a workflow runs like it does on any other commit or pull request. If the workflow succeeds in building and testing the module on Linux, macOS and Windows, a separate <code>Publish.yml</code> workflow runs a publish job if, and only if the previous workflow succeeded, and if <code>github.event.workflow_run.head_branch</code> starts with \"v\".</p>"},{"location":"blog/2024/03/21/new-pspushover-powershell-module/#caching","title":"Caching","text":"<p>While the building and publishing workflows run relatively quickly on this small module, I added some caching using <code>actions/cache</code> and Chrissy LeMaire's <code>potatoqualitee/psmodulecache</code> GitHub Action. All in all, the caches I setup are helping with the python pip cache, the PowerShell module dependencies, and the <code>squidfunk/mkdocs-material</code> docker image which is used for building and pushing the docs site to GitHub Pages.</p> <p></p> <p>The <code>psmodulecache</code> GitHub Action is pretty great, but one thing it didn't allow me to do (yet) was reference my existing PSDepend <code>requirements.psd1</code> file, and I didn't want to declare my PowerShell module dependencies in multiple places. So my workaround was to run a step just before <code>psmodulecache</code> which reads the existing <code>requirements.psd1</code> file, grabs the PowerShell module names and versions, and formats them the way <code>psmodulecache</code> expects them, then writes them to <code>GITHUB_OUTPUT</code>. Then in my <code>modules-to-cache</code> input for <code>psmodulecache</code> I reference the output from the previous step instead of hard-coding dependency names/versions in my workflow files.</p> <p>There was one last \"gotcha\" I ran into with caching PowerShell modules in my GitHub Actions and that was the \"key\" used to identify the cache. The key Chrissy uses is based on the OS, the shell, and then a concatenated list of the dependencies declared in <code>modules-to-cache</code>. Instead of each consecutive build re-using the existing caches, they were generating new caches each time because the module names were in different orders each time. When I realized it's because of the fact that the <code>[hashtable]</code> object uses unordered keys, I updated the workflows to sort the modules before joining them into a comma-separated list and writing them to <code>GITHUB_OUTPUT</code>.</p>"},{"location":"blog/2024/03/21/new-pspushover-powershell-module/#automated-documentation","title":"Automated documentation","text":"<p>Okay it's not completely automated. While I could plug OpenAI into the pipeline to generate some help text for PowerShell commands to use in place of the stubs created by PlatyPS, I haven't done it yet. However, there's a Docs build step in the <code>PowerShellBuild</code> module which is using PlatyPS to create and/or update markdown files for all public cmdlets in the module. All I had to do was fill in the placeholder values for synopsis, descriptions, and examples.</p> <p>I updated the <code>mkdocs.yml</code> file to use the Material for MkDocs theme, made a home page, and added \"online version\" values to the frontmatter for each cmdlet so that you can run <code>Get-Help Send-Pushover -Online</code> in PowerShell to launch a browser to the associated online help.</p> <p>There's a dedicated <code>Docs.yml</code> workflow that runs whenever there's a push to the main branch with a change to anything under <code>docs/</code>, to <code>mkdocs.yml</code>, or to the <code>Docs.yml</code> workflow itself. Then there's also a <code>workflow_dispatch</code> trigger so that I can update the docs manually if at any time I need to. Limiting the scope of files that can trigger an automatic workflow run helps prevent unnecessary jobs from burning up time on GitHub's runners.</p>"},{"location":"blog/2024/03/21/new-pspushover-powershell-module/#pushover-notification-demo","title":"Pushover notification demo","text":"<p>Finally, I had the idea to allow people to subscribe to Pushover notifications sent when someone \"stars\" the GitHub repo as a way to see what the notifications look like without creating their own \"application\" in their Pushover dashboard and running the <code>Send-Pushover</code> cmdlet themselves.</p> <p></p> <p>The <code>NotifyOnStarred.yml</code> workflow is triggered on GitHub's <code>watch</code> event - that's the name of the event that fires when someone stars a repo. Then the version of PSPushover currently on the main branch is imported, and app/user tokens are read from GitHub Action secrets, and a notification is sent to a dynamic Pushover distribution group.</p> <p>If you subscribe to PSPushover notifications you can securely join the distribution group without exposing your real Pushover user token, or even having to know what a token is. You can then star the repo, and in ~15 seconds you'll get a cute little push notification (and so will I!). Then of course you can unsubscribe because who wants extraneous notifications, right?</p>"},{"location":"blog/2024/03/24/image-comparison/","title":"Image Comparison","text":"<p>I recently came across a couple of blog posts on image comparison algorithms shared by Dr. Neal Krawetz. One of them, titled \"Kind Of Like That\", describes the \"dHash\" algorithm which generates a perceptual hash based on gradients in the image. With more than 200k family photos to wrangle, I wrote up a PowerShell implementation to find similar images and it works surprisingly well!</p> <p></p> <p>After almost 20 years of taking pictures and videos with our smart phones, our family photos and videos are scattered between the Google and Apple clouds. In order to make sure all these memories are safe, no matter what happens with our cloud accounts over time, I downloaded everything, and will be following a 3-2-1 backup strategy. That means there will be at least three copies, on two different storage mediums, with one copy offsite.</p>"},{"location":"blog/2024/03/24/image-comparison/#so-many-duplicates","title":"So many duplicates","text":"<p>While trying out a self-hosted instance of PhotoPrism and indexing over 60k files so far, I noticed that a lot of our photos are duplicates. Many of them are exact duplicates and those are easy to find using a traditional SHA hash, but most duplicates are...</p> <ul> <li>resized versions of the original</li> <li>edited to add a border or to change the colors in some way</li> <li>very similar images taken within the same second or two, and not duplicates at all</li> </ul> <p>I'm sure I have enough storage available to just back them all up, but the percentage of wasted space is somewhere around 40% and it just didn't sit well with me. Plus, with so many duplicates, it's frustrating to scroll through the library in apps like PhotoPrism. Tagging faces gets old quickly when you keep seeing the same face in the same photo repeated over and over.</p>"},{"location":"blog/2024/03/24/image-comparison/#the-algorithm","title":"The algorithm","text":"<p>I searched around online to see what my options were in terms of tools, or maybe existing .NET or Python libraries, and that's when I came across one of Dr. Neal Krawetz' blog posts. It's a short and interesting read, and my first introduction to a \"perceptual hash\". If you're interested, please do go check out his blog!</p> <p>I hear and use the word \"hash\" on a regular basis, and have used all kinds of cryptographic hashes over the years including md5, bcrypt, and the various sha's. But these are fundamentally different algorithms with almost polar opposite goals. The kind of hashs I was familar with were designed to produce wildly different results from two sets of data if even a single bit was different between them. The resulting hashes were either the same, indicating that the inputs were very likely the same (collisions happen, but they're hard to find), or they were different, indicating that the inputs were definitely different. There should be no way to measure how similar two inputs are based on their SHA hashes. If you could, the algorithm would be too weak to use for any kind of security or privacy on the web.</p> <p>In contrast, a perceptual hash like dHash will, by design, produce the same or similar hash when given two images that are nearly identical. And since each bit in the 64bit hash represents a part of the image, you can calculate the hamming distance between two hashes to determine how many of the 64bits in the two hashes are different. Fewer differences indicate a higher likelihood that the hashes are from the same or similar images.</p> <p>Here's a quick summary of the dHash algorithm:</p> <ol> <li>Reduce the size to 9x8 pixels. Don't worry about the original image size or aspect ratio.</li> <li>Convert to grayscale because we only care about the \"brightness\" of each pixel.</li> <li>Compare each pixel's brightness to the neighbor on the right. This is why the image is resized to 9x8 - we need 8 bits per row.</li> <li>Assign a bit value of \"1\" if the current pixel is brighter than the neighbor on the right.</li> </ol> <p>You will end up with one byte per row, and 8 rows, for a total of 64 bits. Convert the array of bytes to a hexadecimal string and you have your dHash.</p>"},{"location":"blog/2024/03/24/image-comparison/#examples","title":"Examples","text":""},{"location":"blog/2024/03/24/image-comparison/#nearly-identical","title":"Nearly identical","text":"<p>These photos of my daughter at the river are nearly identical to the untrained eye, but the raw files are very different. In the following table you'll find a side-by-side comparison of what appears to be the same image, and their dHashes along with a SHA1. For fun, you'll also find the 9x8 grayscale versions from which the dHashes were derived.</p> <p>The hamming distance between the dHash values from these images is 2, which means two out of the 64 bits of the hash were different, so as you would expect, the hash comparison shows that the images have a strong visual similarity.</p> Photo 1 Photo 2 dHash: 41304c4be436784c dHash: 41204c49e436784c SHA1: 80187EB0E86F2FCDE82E60D7CD53BB0B1B1FF686 SHA1: 5BC13493BB94536C3EAE794A924C1D9A00D207D6"},{"location":"blog/2024/03/24/image-comparison/#image-filter-applied","title":"Image filter applied","text":"<p>In this next example, the first image is the original and the second has been \"color enhanced\". We can see that the images are definitely different, but we can also see that they're most likely the same image with different colors. Once again, when we compare the dHashes, we get a difference of 2. Since that is well under 10, we can be fairly confident that the images are similar.</p> Photo 3 Photo 4 dHash: 60606040587c5c7c dHash: 60606040d87c5d7c SHA1: BDE8B4AB0DC4E28D4DA72A982E4B99159E72EA9C SHA1: C624DC07813ABBC07E286665AF7A41941F19F9AF"},{"location":"blog/2024/03/24/image-comparison/#very-different-cats","title":"Very different cats","text":"<p>Okay in this last example, just to demonstrate that the algorithm doesn't consider all images similar, here are two very different cats because... internet. The dHash comparison returns a value of 20.</p> Photo 5 Photo 6 dHash: 564e7c6cee3f526e dHash: 54ccace8e8cbe67e SHA1: 51E2DFE65974C86740C314E7883D22C163D3EA1B SHA1: A58DBDAA875B5FC311BBB35A74748E68550CFC12"},{"location":"blog/2024/03/24/image-comparison/#code","title":"Code","text":"<p>Here's the code so far. The idea was that the cmdlets should work similar to the way the <code>Get-FileHash</code> cmdlet works, so the output of <code>Get-PerceptHash</code> is a <code>[PSCustomObject]</code> with an Algorithm, Hash, and Path property. When I get around to it, I think I'll implement additional perception hashes incuding aHash and pHash as described by Dr. Neal Krawetz, but for now only the dHash algorithm is implemented here.</p> <p>Later, I'll post an update with another potential use-case for this - comparison of video surveillance images for the purpose of checking whether a camera has been obscured or moved. I'm not sure the reliability is good enough to use on it's own, but I'm thinking it should be relatively easy to do multiple types of perception hashes and edge detection to produce a sort of composite hash for better accuracy.</p> <p>Download </p> PerceptHash.psm1<pre><code>using namespace System.IO\nusing namespace System.Management.Automation\n\nfunction Get-DHash {\n    &lt;#\n    .SYNOPSIS\n    Computes the dHash value for the provided image.\n    .DESCRIPTION\n    The `Get-DHash` cmdlet computes the dHash value for the provided image. The dHash is a 64-bit representation of the\n    image, returned as a hexadecimal string. The dHash values for two images can be compared using Compare-DHash, and\n    the resulting value represents the number of bits that are different between the two images, or the\n    \"Hamming distance\".\n    The dHash is computed using the following algorithm. See the blog post referenced in the notes for more information.\n    1. Convert the image to grayscale.\n    2. Resize the image to 9x8.\n    3. For each of the 8 rows in the resulting image, check if each pixel is brighter than the neighbor to the right. If\n       it is, that bit is set to 1.\n    4. Convert the 8 resulting bytes to a hexadecimal string.\n    .PARAMETER Path\n    Specifies the path to an image file.\n    .PARAMETER Bytes\n    Specifies an array of bytes representing an image.\n    .PARAMETER OutFile\n    For diagnostic purposes, you may provide a path to save the resized, grayscale representation of the provided image created for dHash calculation.\n    .PARAMETER ColorMatrix\n    Optionally you may provide a custom ColorMatrix used to create a grayscale representation of the source image.\n    .EXAMPLE\n    $dhash1 = Get-DHash ./image1.jpg\n    $dhash2 = Get-DHash ./image2.jpg\n    Compare-DHash $dhash1 $dhash2\n    Computes the dHash values for two different images, and then compares the\n    dHash values. The result is the number of bits that do not match between the\n    two difference-hashes.\n    .NOTES\n    The inspiration for the dHash concept and these functions comes from a blog\n    post by Dr. Neal Krawetz on [The Hacker Factor Blog](https://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html).\n    #&gt;\n    [CmdletBinding(DefaultParameterSetName = 'Path')]\n    [OutputType([string])]\n    param (\n        [Parameter(Mandatory, Position = 0, ValueFromPipeline, ValueFromPipelineByPropertyName, ParameterSetName = 'Path')]\n        [string]\n        $Path,\n\n        [Parameter(Mandatory, Position = 0, ValueFromPipelineByPropertyName, ParameterSetName = 'LiteralPath')]\n        [Alias('PSPath')]\n        [Alias('LP')]\n        [string]\n        $LiteralPath,\n\n        [Parameter(Mandatory, Position = 0, ParameterSetName = 'Stream')]\n        [System.IO.Stream]\n        $InputStream,\n\n        # Saves a copy of the grayscale, resized reference image used for calculating dHash for diagnostic purposes.\n        [Parameter(ParameterSetName = 'Path')]\n        [Parameter(ParameterSetName = 'LiteralPath')]\n        [Parameter(ParameterSetName = 'Stream')]\n        [string]\n        $OutFile,\n\n        [Parameter(ParameterSetName = 'Path')]\n        [Parameter(ParameterSetName = 'LiteralPath')]\n        [Parameter(ParameterSetName = 'Stream')]\n        [float[]]\n        $ColorMatrix = @(0.299, 0.587, 0.114)\n    )\n\n    begin {\n        Add-Type -AssemblyName System.Drawing\n    }\n\n    process {\n        if ($PSCmdlet.ParameterSetName -ne 'Stream') {\n            if (-not [string]::IsNullOrWhiteSpace($Path)) {\n                $LiteralPath = (Resolve-Path -Path $Path).ProviderPath\n            } else {\n                $LiteralPath = (Resolve-Path -LiteralPath $LiteralPath).ProviderPath\n            }\n            foreach ($filePath in $LiteralPath) {\n                try {\n                    $null = Resolve-Path -LiteralPath $filePath -ErrorAction Stop\n                    $stream = [file]::Open($filePath, [filemode]::Open, [fileaccess]::Read, [fileshare]::Read)\n                    $params = @{\n                        InputStream = $stream\n                        ColorMatrix = $ColorMatrix\n                    }\n                    if (-not [string]::IsNullOrWhiteSpace($OutFile)) {\n                        $params.OutFile = $OutFile\n                    }\n                    Get-DHash @params\n                } catch {\n                    Write-Error -ErrorRecord $_\n                } finally {\n                    if ($stream) {\n                        $stream.Dispose()\n                    }\n                }\n            }\n            return\n        }\n        try {\n            $dHash = [byte[]]::new(8)\n            $src = [drawing.image]::FromStream($InputStream)\n            $dst = ConvertTo-DHashImage -Image $src\n            for ($y = 0; $y -lt $dst.Height; $y++) {\n                $byte = [byte]0\n                for ($x = 0; $x -lt ($dst.Width - 1); $x++) {\n                    $thisPixel = $dst.GetPixel($x, $y).GetBrightness()\n                    $nextPixel = $dst.GetPixel($x + 1, $y).GetBrightness()\n                    $thisPixelIsBrighter = [byte]($thisPixel -gt $nextPixel)\n                    $byte = $byte -shl 1\n                    $byte = $byte -bor $thisPixelIsBrighter\n                }\n                $dHash[$y] = $byte\n            }\n            ConvertTo-HexString -InputObject $dHash\n\n            if ($PSCmdlet.MyInvocation.BoundParameters.ContainsKey('OutFile')) {\n                $OutFile = $ExecutionContext.SessionState.Path.GetUnresolvedProviderPathFromPSPath($OutFile)\n                $dst.Save($OutFile, [System.Drawing.Imaging.ImageFormat]::Jpeg)\n            }\n        } finally {\n            $src, $dst | Where-Object { $null -ne $_ } | ForEach-Object {\n                $_.Dispose()\n            }\n        }\n    }\n}\n\nfunction Compare-DHash {\n    &lt;#\n    .SYNOPSIS\n    Compares the provided dHash strings and returns the difference as an integer between 0 and 64.\n    .DESCRIPTION\n    The `Compare-DHash` cmdlet compares the provided dHash strings and returns the difference as an\n    integer between 0 and 64.\n    .PARAMETER DHash1\n    Specifies a case-insensitive dHash string with 16 hexadecimal characters.\n    .PARAMETER DHash2\n    Specifies a case-insensitive dHash string with 16 hexadecimal characters.\n    .EXAMPLE\n    $dhash1 = Get-DHash ./image1.jpg\n    $dhash2 = Get-DHash ./image2.jpg\n    Compare-DHash $dhash1 $dhash2\n    Computes the dHash values for two different images, and then compares the\n    dHash values. The result is the number of bits that do not match between the\n    two difference-hashes.\n    .NOTES\n    The inspiration for the dHash concept and these functions comes from a blog\n    post by Dr. Neal Krawetz on [The Hacker Factor Blog](https://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html).\n    #&gt;\n    [CmdletBinding()]\n    [OutputType([int])]\n    param (\n        [Parameter(Mandatory, Position = 0)]\n        [string]\n        $DHash1,\n\n        [Parameter(Mandatory, Position = 1)]\n        [string]\n        $DHash2\n    )\n\n    process {\n        $difference = 0;\n        for ($index = 0; $index -lt 8; $index++) {\n            $byte1 = [convert]::ToByte($DHash1.SubString($index * 2, 2), 16)\n            $byte2 = [convert]::ToByte($DHash2.SubString($index * 2, 2), 16)\n            $xor = $byte1 -bxor $byte2\n            for ($bit = 8; $bit -gt 0; $bit--) {\n                $difference += $xor -band 1\n                $xor = $xor -shr 1\n            }\n        }\n        $difference\n    }\n}\n\nfunction ConvertFrom-HexString {\n    [CmdletBinding()]\n    [OutputType([byte[]])]\n    param (\n        [Parameter(Mandatory, Position = 0, ValueFromPipeline)]\n        [string]\n        $InputObject\n    )\n\n    process {\n        $bytes = [byte[]]::new($InputObject.Length / 2)\n        for ($index = 0; $index -lt $bytes.Length; $index++) {\n            $bytes[$index] = [convert]::ToByte($InputObject.SubString($index * 2, 2), 16)\n        }\n        Write-Output $bytes -NoEnumerate\n    }\n}\n\nfunction ConvertTo-HexString {\n    [CmdletBinding()]\n    [OutputType([string])]\n    param (\n        [Parameter(Mandatory, Position = 0)]\n        [byte[]]\n        $InputObject\n    )\n\n    process {\n        [string]::Join('', ($InputObject | ForEach-Object { $_.ToString('x2') }))\n    }\n}\n\nfunction ConvertTo-DHashImage {\n    &lt;#\n    .SYNOPSIS\n    Returns a grayscale 9x8 resolution image based on the input image.\n    .DESCRIPTION\n    The `ConvertTo-DHashImage` cmdlet returns a grayscale 9x8 resolution image\n    based on the input image.\n    .PARAMETER Image\n    Specifies the input image.\n    .PARAMETER ColorMatrix\n    Optionally specifies the RGB values to use in the ColorMatrix used for grayscale conversion.\n    .EXAMPLE\n    [System.Drawing.Image]::FromFile('C:\\path\\to\\image.jpg') | ConvertTo-DHashImage\n    Create a new System.Drawing.Image object from image.jpg, and produce a grayscale 9x8 representation of it.\n    #&gt;\n    [CmdletBinding()]\n    [OutputType([System.Drawing.Image])]\n    param (\n        [Parameter(Mandatory, ValueFromPipeline, Position = 1)]\n        [System.Drawing.Image]\n        $Image,\n\n        [Parameter()]\n        [float[]]\n        $ColorMatrix = @(0.299, 0.587, 0.114)\n    )\n\n    process {\n        $r = $ColorMatrix[0]\n        $g = $ColorMatrix[1]\n        $b = $ColorMatrix[2]\n        $grayScale = [float[][]]@(\n            [float[]]@($r, $r, $r, 0, 0),\n            [float[]]@($g, $g, $g, 0, 0),\n            [float[]]@($b, $b, $b, 0, 0),\n            [float[]]@( 0, 0, 0, 1, 0),\n            [float[]]@( 0, 0, 0, 0, 1)\n        )\n\n        try {\n            $dst = [drawing.bitmap]::new(9, 8)\n            $dstRectangle = [drawing.rectangle]::new(0, 0, $dst.Width, $dst.Height)\n            $graphics = [drawing.graphics]::FromImage($dst)\n            $graphics.CompositingMode = [drawing.drawing2d.compositingmode]::SourceOver\n            $graphics.CompositingQuality = [drawing.drawing2d.CompositingQuality]::HighQuality\n            $graphics.InterpolationMode = [drawing.drawing2d.InterpolationMode]::HighQualityBicubic\n            $graphics.PixelOffsetMode = [drawing.drawing2d.PixelOffsetMode]::None\n            $imgAttr = [drawing.imaging.imageattributes]::new()\n            $imgAttr.SetWrapMode([drawing.drawing2d.wrapmode]::Clamp)\n            $imgAttr.SetColorMatrix([drawing.imaging.colormatrix]::new($grayScale))\n            $graphics.DrawImage($Image, $dstRectangle, 0, 0, $Image.Width, $Image.Height, [drawing.graphicsunit]::Pixel, $imgAttr)\n            $dst\n        } finally {\n            $imgAttr, $graphics | Where-Object { $null -ne $_ } | ForEach-Object {\n                $_.Dispose()\n            }\n        }\n    }\n}\n\nfunction Get-PerceptHash {\n    [CmdletBinding(DefaultParameterSetName = 'Path')]\n    [OutputType([pscustomobject])]\n    param(\n        [Parameter(Mandatory, ValueFromPipeline, ValueFromPipelineByPropertyName, Position = 0, ParameterSetName = 'Path')]\n        [string[]]\n        $Path,\n\n        [Parameter(Mandatory, ValueFromPipelineByPropertyName, Position = 0, ParameterSetName = 'LiteralPath')]\n        [Alias('PSPath')]\n        [Alias('LP')]\n        [string[]]\n        $LiteralPath,\n\n        [Parameter(Mandatory, Position = 0, ParameterSetName = 'Stream')]\n        [System.IO.Stream]\n        $InputStream,\n\n        [Parameter(Position = 1, ParameterSetName = 'Path')]\n        [Parameter(Position = 1, ParameterSetName = 'LiteralPath')]\n        [Parameter(Position = 1, ParameterSetName = 'Stream')]\n        [ValidateSet('aHash', 'dHash', 'pHash', IgnoreCase = $true)]\n        [string]\n        $Algorithm = 'dHash'\n    )\n\n    process {\n        if ($Algorithm -ne 'dHash') {\n            throw \"Sorry, the $Algorithm algorithm is not yet implemented. Try dHash instead.\"\n        }\n        if ($PSCmdlet.ParameterSetName -ne 'Stream') {\n            if ($Path.Count -gt 0) {\n                $LiteralPath = (Resolve-Path -Path $Path).ProviderPath\n            } else {\n                $LiteralPath = (Resolve-Path -LiteralPath $LiteralPath).ProviderPath\n            }\n            foreach ($filePath in $LiteralPath) {\n                try {\n                    $null = Resolve-Path -LiteralPath $filePath -ErrorAction Stop\n                    $stream = [file]::Open($filePath, [filemode]::Open, [fileaccess]::Read, [fileshare]::Read)\n                    Get-PerceptHash -InputStream $stream -Algorithm $Algorithm\n                } catch {\n                    Write-Error -ErrorRecord $_\n                } finally {\n                    if ($stream) {\n                        $stream.Dispose()\n                    }\n                }\n            }\n            return\n        }\n        [pscustomobject]@{\n            PSTypeName  = 'PerceptHash'\n            Algorithm = $Algorithm\n            Hash      = Get-DHash -InputStream $stream\n            Path      = $filePath\n        }\n    }\n}\n\nfunction Compare-PerceptHash {\n    &lt;#\n    .SYNOPSIS\n    Compares the provided perception hashes and returns the difference as an integer.\n    .DESCRIPTION\n    The `Compare-PerceptHash` cmdlet compares the provided perception hashes and\n    returns the difference as an integer. A value of 10 or less indicates strong\n    visual similarity. A value of 0 indicates very strong visual similarity, though\n    because the comparison is based on highly compressed versions of the original\n    images, a value of 0 does not guarantee the images are the same.\n\n    .PARAMETER ReferenceHash\n    Specifies a case-insensitive hexadecimal string.\n\n    .PARAMETER DifferenceHash\n    Specifies a case-insensitive hexadecimal string.\n\n    .EXAMPLE\n    $dhash1 = Get-PerceptHash ./image1.jpg\n    $dhash2 = Get-PerceptHash ./image2.jpg\n    $dhash1, $dhash2 | Compare-PerceptHash\n\n    Computes the dHash values for two different images, and then compares the\n    dHash values. The result is the number of bits that do not match between the\n    two difference-hashes.\n\n    .NOTES\n    The inspiration for the dHash concept and these functions comes from a blog\n    post by Dr. Neal Krawetz on [The Hacker Factor Blog](https://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html).\n    #&gt;\n    [CmdletBinding(DefaultParameterSetName = 'default')]\n    [OutputType([int])]\n    param (\n        [Parameter(Mandatory, ValueFromPipeline, ValueFromPipelineByPropertyName, ParameterSetName = 'InputObject')]\n        [Alias('Hash')]\n        [string[]]\n        $InputObject,\n\n        [Parameter(Mandatory, Position = 0, ParameterSetName = 'default')]\n        [string]\n        $ReferenceHash,\n\n        [Parameter(Mandatory, Position = 1, ParameterSetName = 'default')]\n        [string]\n        $DifferenceHash\n    )\n\n    process {\n        foreach ($hash in $InputObject) {\n            if ($PSCmdlet.ParameterSetName -eq 'InputObject') {\n                if ([string]::IsNullOrWhiteSpace($ReferenceHash)) {\n                    $ReferenceHash = $hash\n                    continue\n                } elseif ([string]::IsNullOrWhiteSpace($DifferenceHash)) {\n                    $DifferenceHash = $hash\n                    continue\n                } else {\n                    throw \"Too many hashes have been provided for comparison. Please provide only two hashes at a time.\"\n                }\n            }\n        }\n    }\n\n    end {\n        try {\n            $difference = 0;\n            for ($index = 0; $index -lt 8; $index++) {\n                $byte1 = [convert]::ToByte($ReferenceHash.SubString($index * 2, 2), 16)\n                $byte2 = [convert]::ToByte($DifferenceHash.SubString($index * 2, 2), 16)\n                $xor = $byte1 -bxor $byte2\n                for ($bit = 8; $bit -gt 0; $bit--) {\n                    $difference += $xor -band 1\n                    $xor = $xor -shr 1\n                }\n            }\n            $difference\n        } catch {\n            Write-Error -ErrorRecord $_\n        }\n    }\n}\n\nExport-ModuleMember -Function Get-PerceptHash, Compare-PerceptHash\n</code></pre>"},{"location":"blog/2024/03/25/but-i-am-the-administrator/","title":"But I AM the administrator","text":"<p>A while back I was helping a co-worker with a project where the customer needed to automate a lot of minor Windows configuration steps on some Windows IoT server appliances. One of the tasks was to make it possible to disable Windows Firewall, because even an administrator was greeted with the message \"For your security, some settings are managed by your system administrator\" and the option to change firewall settings was disabled.</p> <p>While I don't agree with disabling the firewall, they weren't my or my organizations computers and the customer needed to be able to task their distributor with pre-configuring hundreds or maybe thousands of systems identically without Active Directory or Azure AD.</p> <p>System administration or provisioning isn't my role but I'm familiar enough with Windows to automate most thing that come up. I figured there would be a cmdlet or command-line tool baked into the OS that would make quick work of this, but as I dug into it, the only option seemed to be to apply a GPO or use the interactive netsh prompt.</p> <p>Maybe there's a better way, and you should really just keep the firewall enabled with whatever rules you require, but I wrote this function to run those interactive netsh commands in a way that could be automated.</p>"},{"location":"blog/2024/03/25/but-i-am-the-administrator/#code","title":"Code","text":"<p>Download </p> Set-FirewallGpo.ps1<pre><code>function Set-FirewallGpo {\n    &lt;#\n    .SYNOPSIS\n    Sets the Windows Firewall local security policy for one or more network profiles.\n\n    .DESCRIPTION\n    If the Windows Firewall cannot be manually enabled, or disabled for one or more\n    network profiles and you see a message similar to \"For your security, some\n    settings are managed by your system administrator\", it means that the settings\n    are managed either by group policy enforced by your organization, or the local\n    security policy in the Windows host machine.\n\n    The manual method to set this local security policy is to launch the \"Local\n    Security Policy\" dialog (secpol.msc), and open the properties for\n    \"Security Settings &gt; Windows Defender Firewall with Advanced Security - Local Group Policy Object\"\n    and modify the state for each of the three profiles - Domain, Private, and\n    Public. Note that this should only be done if this setting is NOT managed by\n    your organization, and you are entitled to modify the local security policy\n    of the Windows machine in question.\n\n    The command-line method is to use the netsh CLI. Unfortunately, it seems like\n    even with the latest edition of Windows 11 and Server 2022, there is no native\n    PowerShell cmdlet or one-line netsh command to modify the Windows Firewall\n    local group policy object. The following netsh commands will get the job\n    done. Be sure to replace \"&lt;hostname&gt;\" with the real machine hostname,\n    \"&lt;ProfileName&gt;\"\" with one of \"allprofiles\", \"domainprofile\", \"privateprofile\",\n    or \"publicprofile\", and \"&lt;State&gt;\" with one of \"On\", \"Off\", or \"NotConfigured\".\n\n    C:\\&gt; netsh\n    netsh&gt; advfirewall\n    netsh advfirewall&gt; set store gpo=&lt;hostname&gt;\n    Ok.\n\n    netsh advfirewall&gt;set &lt;ProfileName&gt; state &lt;State&gt;\n    Ok.\n\n    To do this in one line, you can provide multiple \"standard input\" values to\n    enter the advfirewall context in netsh like so:\n\n    \"advfirewall\", \"set store gpo=$(hostname)\", \"set AllProfiles state NotConfigured\" | netsh\n\n    Manually typing commands at the netsh CLI is not useful for automation, so\n    this cmdlet launches the netsh CLI and types the commands for you. If the\n    command fails with a non-zero exit code, the output from the CLI is provided\n    in an error, or you can use -PassThru to receive the results from the\n    process including the exit code, and standard output and standard error\n    content.\n\n    .PARAMETER ProfileName\n    Specifies the network profile to which to apply the policy change.\n\n    .PARAMETER State\n    Specifies the new state for the Windows Firewall for the specified network\n    profile(s).\n\n    .PARAMETER PassThru\n    Specifies that the raw exit code, stdout, and stderr should be returned to\n    the caller.\n\n    .EXAMPLE\n    Set-FirewallGpo -ProfileName AllProfiles -State NotConfigured\n    Set-NetFirewallProfile -All -Enabled True\n\n    Sets the firewall policy for all network profiles to \"NotConfigured\" which\n    means that as a local Administrator you can enable or disable the Windows\n    Firewall for any profile. Then enables the firewall for all profiles.\n\n    #&gt;\n    [CmdletBinding(SupportsShouldProcess)]\n    param(\n        [Parameter()]\n        [ValidateSet('AllProfiles', 'DomainProfile', 'PrivateProfile', 'PublicProfile')]\n        [string]\n        $ProfileName = 'AllProfiles',\n\n        [Parameter(Mandatory)]\n        [ValidateSet('On', 'Off', 'NotConfigured')]\n        [string]\n        $State,\n\n        [Parameter()]\n        [switch]\n        $PassThru\n    )\n\n    process {\n        if (-not $PSCmdlet.ShouldProcess((hostname), \"Set Firewall local security policy for profile '$ProfileName' to '$State'\")) {\n            return\n        }\n        try {\n            $pinfo = [System.Diagnostics.ProcessStartInfo]@{\n                FileName               = 'netsh'\n                Arguments              = ''\n                WorkingDirectory       = (Resolve-Path .\\).Path\n                UseShellExecute        = $false\n                CreateNoWindow         = $true\n                RedirectStandardOutput = $true\n                RedirectStandardError  = $true\n                RedirectStandardInput  = $true\n            }\n\n            $p = [System.Diagnostics.Process]::Start($pInfo)\n            $p.StandardInput.WriteLine('advfirewall')\n            $p.StandardInput.WriteLine(\"set store gpo=$(hostname)\")\n            $p.StandardInput.WriteLine(\"set $ProfileName state $State\")\n            $p.StandardInput.WriteLine('exit')\n\n            $stringBuilder = [text.stringbuilder]::new()\n            while ($null -ne ($line = $p.StandardOutput.ReadLine())) {\n                $null = $stringBuilder.AppendLine($line.Trim())\n            }\n            $stdout = $stringBuilder.ToString()\n\n            $null = $stringBuilder.Clear()\n            while ($null -ne ($line = $p.StandardError.ReadLine())) {\n                $null = $stringBuilder.AppendLine($line.Trim())\n            }\n            $stderr = $stringBuilder.ToString()\n\n            Write-Verbose \"Waiting for process $($p.Id) to exit\"\n            $p.WaitForExit()\n            if ($p.ExitCode -ne 0) {\n                $message = '{0} exited with exit code {1}. {2}' -f $pinfo.FileName, $p.ExitCode, ($stdout + $stderr)\n                Write-Error -Message $message\n            }\n\n            if ($PassThru) {\n                [pscustomobject]@{\n                    Process        = $p\n                    ExitCode       = $p.ExitCode\n                    StandardOutput = $stdout\n                    StandardError  = $stderr\n                }\n            }\n        } catch {\n            Write-Error -ErrorRecord $_\n        }\n    }\n}\n</code></pre>"},{"location":"blog/2024/05/12/serving-a-web-api-with-pode/","title":"Serving a web api with Pode","text":"<p>I added a subtle \"Now playing\" text to the footer of this site which represents the first result in the response from the user.getRecentTracks method on the Last.FM API. The data is updated every few seconds with a little bit of JavaScript by polling a small Pode web service running in my home lab.</p> <p></p> <p>Could I have polled Last.FM's API directly from this website? Absolutely. But then I would have no control over how frequently my API key is used to poll the Last.FM API which means there's a risk (as low as it is) of being rate-limited, and even more problematic is that I would have to expose my API key to the client. Remember - never trust anyone or anything connecting to your web service to keep a secret - especially a secret that doesn't expire. If you wouldn't send the information to an internet-stranger, don't embed it into a webpage.</p> <p>To avoid exposing any credentials, minimize the API surface area exposed to the client, and ultimately just for the fun of it, I created a small Docker image hosting a tiny Pode app. Are there more efficient tools for serving a simple web API? Probably. Do they let me do it in PowerShell? Probably not.</p>"},{"location":"blog/2024/05/12/serving-a-web-api-with-pode/#a-little-context","title":"A little context","text":"<p>I was 21 years old in 2006 which is roughly the last time I tried to do anything interesting with JavaScript. The above image is a screenshot of Winamp - one of the most popular media players of the time (it really whips the llama's ass!), except it looks like it's running in the browser.</p> <p></p> <p>There was no browser-based Winamp at the time though as far as I'm aware. I had painstakingly sliced screenshots of the Winamp interface and stitched them together in HTML. I then populated that interface with live data from a Winamp plugin which I think was called \"Snow Crash\" (yep, like the novel). The buttons, playlist, and scrollbars were all wired up so you could control the Winamp instance running on my computer, and while I don't have a screenshot of it, I also added a simple \"Now playing\" control to my hand-made blog I was using at the time.</p> <p></p> <p>Lately I've been using Navidrome to serve my music from a container in my home lab as it has a nice web interface, and it's compatible with the Subsonic API which makes it possible to use with a variety of Android/iOS apps with support for caching and downloading tracks.</p> <p>I remembered that old Winamp remote and thought it would be a fun exercise or code kata to get a live \"Now playing...\" message on my blog again.</p>"},{"location":"blog/2024/05/12/serving-a-web-api-with-pode/#dockerfile","title":"Dockerfile","text":"<p>Initially my dockerfile included an embedded copy of my Pode app files, <code>packages.json</code> and <code>server.ps1</code>, but I quickly realized it would be better for the container image to simply include the Pode module, and a default entrypoint so that you can supply your Pode app at runtime rather than at buildtime. So an already relatively simple dockerfile became even more simple.</p> File: Dockerfile<pre><code>FROM mcr.microsoft.com/powershell:7.4-alpine-3.17\nWORKDIR /app\nSHELL [ \"pwsh\", \"-NoLogo\", \"-NoProfile\", \"-Command\" ]\nRUN Install-Module pode -Scope AllUsers -Force\nENTRYPOINT [ \"pwsh\", \"-c\", \"pode\" ]\nCMD [ \"start\" ]\nEXPOSE 80\n</code></pre>"},{"location":"blog/2024/05/12/serving-a-web-api-with-pode/#docker-compose","title":"Docker Compose","text":"<p>I already run several applications at home, and most of them run in containers behind Traefik, so it seemed natural to run this the same way. Traefik routes all the inbound HTTP/S connections it receives from my network firewall to the appropriate service primarily based on labels on those services in the <code>compose.yml</code> Docker Compose files.</p> <p>In this case, I'm using the following compose file to describe the service, including when Traefik should route requests to it. The Last.FM environment variables are supplied from an external <code>.env</code> file so that the <code>compose.yml</code> file can be safely shared or commited to git.</p> File: compose.yml<pre><code>services:\n  homelab:\n    image: joshooaj/homelabapi:latest\n    build:\n      dockerfile: dockerfile\n    restart: unless-stopped\n    environment:\n      LASTFM_USER: ${LASTFM_API_USER}\n      LASTFM_API_KEY: ${LASTFM_API_KEY}\n    volumes:\n      - ./app:/app\n    networks:\n      - web\n    labels:\n      - traefik.enable=true\n      - traefik.http.routers.homelab.entrypoints=https\n      - traefik.http.routers.homelab.rule=Host(`homelab.joshooaj.com`)\n      - traefik.http.routers.homelab.middlewares=cors\n      - traefik.http.middlewares.cors.headers.accesscontrolalloworiginlist=https://www.joshooaj.com\n      - traefik.http.services.homelab.loadbalancer.server.port=80\nnetworks:\n  web:\n    name: web-secure\n    external: true\n</code></pre> <p>By running <code>docker compose build</code> in the same folder as the <code>compose.yml</code> and the <code>dockerfile</code> referenced by the compose file, the container image is built and tagged according to the compose file. Now I just need to supply the files for the Pode app, and \"up\" the service with <code>docker compose up -d</code>.</p>"},{"location":"blog/2024/05/12/serving-a-web-api-with-pode/#pode-app","title":"Pode app","text":"<p>To start, I ran the <code>pode init</code> command to generate a <code>package.json</code> file. I was prompted for a few bits of information before a simple <code>packages.json</code> file was stubbed out for me.</p> pode init<pre><code>PS&gt; pode init\n\nname (temp): homelab\nversion (1.0.0):\ndescription: API endpoint for exposed homelab information\nentry point (./server.ps1):\nauthor: joshooaj\nlicense (MIT):\nSuccess, saved package.json\n</code></pre> File: app/package.json<pre><code>{\n    \"version\": \"1.0.0\",\n    \"main\": \"./server.ps1\",\n    \"author\": \"joshooaj\",\n    \"name\": \"homelab\",\n    \"description\": \"API endpoint for exposed homelab information\",\n    \"scripts\": {\n        \"test\": \"invoke-pester ./tests/*.ps1\",\n        \"install\": \"yarn install --force --ignore-scripts --modules-folder pode_modules\",\n        \"build\": \"psake\",\n        \"start\": \"./server.ps1\"\n    },\n    \"license\": \"MIT\"\n}\n</code></pre> <p>Then I created a <code>server.ps1</code> file since that was the default file name referenced as the entrypoint in the <code>package.json</code> file produced in the previous step. Here is the <code>server.ps1</code> file responsible for providing a list of recent tracks.</p> File: app/server.ps1<pre><code>param(\n    # Listen on all IPv4 interfaces by default\n    [Parameter()]\n    [string]\n    $Address = '0.0.0.0',\n\n    # Listen on port 8088 by default\n    [Parameter()]\n    [ValidateRange(0, 65535)]\n    [int]\n    $Port = 80\n)\n\nStart-PodeServer {\n    Add-PodeEndpoint -Address $Address -Port $Port -Protocol Http # (1)!\n\n    # Log requests to the terminal/stdout\n    New-PodeLoggingMethod -Terminal -Batch 10 -BatchTimeout 10 | Enable-PodeRequestLogging\n    New-PodeLoggingMethod -Terminal | Enable-PodeErrorLogging\n\n    $messagesRouteParams = @{\n        Method      = 'Get'\n        Path        = '/music/recenttracks'\n        ContentType = 'application/json'\n    }\n    Add-PodeRoute @messagesRouteParams -ScriptBlock {\n        # (2)!\n        $cachedTracks = Get-PodeState -Name 'recenttracks'\n        $uri = \"https://ws.audioscrobbler.com/2.0/?method=user.getrecenttracks&amp;user=$($env:LASTFM_USER)&amp;api_key=$($env:LASTFM_API_KEY)&amp;format=json\"\n        if ($null -eq $cachedTracks -or $cachedTracks.TimeStamp -lt (Get-Date).AddMinutes(-1)) {\n            Set-PodeState -Name recenttracks -Value (\n                [pscustomobject]@{\n                    TimeStamp = Get-Date\n                    Tracks    = (Invoke-RestMethod -Method Get -Uri $uri -ErrorAction Stop).recenttracks.track\n                })\n        }\n\n        # (3)!\n        $limit = 50\n        if ($WebEvent.Query['limit']) {\n            $limit = [math]::Min($limit, [math]::Abs([int]$WebEvent.Query['limit']))\n        }\n\n        # (4)!\n        $response = @{\n            StatusCode = 200\n            Value      = (Get-PodeState -Name 'recenttracks').Tracks | Select-Object -First $limit\n        }\n        Write-PodeJsonResponse @response\n    }\n}\n</code></pre> <ol> <li>Pode will run in a container behind a reverse proxy (Traefik) which will expose this as an HTTPS service so HTTP is    fine here.</li> <li>Only call Last.FM API if there is no previous cached response or the last response is older than 1 minute.</li> <li>The API always returns 50 tracks but if the \"limit\" query param is provided, only return that many.</li> <li>Build response with cached value of \"recenttracks\" and filter response to the first $limit records.</li> </ol>"},{"location":"blog/2022/12/07/your-users-deserve-argument-completers/","title":"Your users deserve argument completers","text":""},{"location":"blog/2022/12/07/your-users-deserve-argument-completers/#introduction","title":"Introduction","text":"<p>One of the things I love about PowerShell is the focus on usability and discoverability. The PowerShell team, and the community, have invested so much into reducing friction and accelerating your workflow. Argument completers are one of the tools available to you, and you should consider adding them to your projects if you aren't doing so already.</p> <p>An argument completer is a scriptblock that you can associate with a named parameter on one or more commands using the <code>Register-ArgumentCompleter</code> cmdlet. Then, when a user types that command followed by the parameter name, the argument completer is invoked. The completer receives information about the command, parameter, the characters already entered by the user (if any), along with a hashtable with the names and values of any other parameters the user has specified so far for that command.</p> <p>With this information, you can then provide the user with a list of completions. As an example, when you type <code>Get-ChildItem -</code> and then press <code>TAB</code> or <code>CTRL+Space</code>, you will get a list of files and folders in the current directory. And if you type the first few letters of the path you want, the list of argument completions narrows down to only those paths beginning with those few letters.</p> <p>I don't think it can be overstated how much it improves the user experience and accelerates people when argument completion is implemented everywhere it makes sense. This is a feature of PowerShell that I wasn't aware of when I first started to build the MilestonePSTools module and in the last year or so I have started adding them wherever I can.</p> <p>The jury is still out on how much this is appreciated by MilestonePSTools users but even if I'm the only one who appreciates them, it's still a win because they improve my quality, enable me to work faster, and reduce frustration and fatigue.</p>"},{"location":"blog/2022/12/07/your-users-deserve-argument-completers/#introducing-get-parentprocess","title":"Introducing Get-ParentProcess","text":"<p>Let's start by defining a new function called <code>Get-ParentProcess</code> which will accept either a process name, or ID, and return a <code>[pscustomobject]</code> with the name and ID of the original process, and the name and ID of the parent process. Why? Because this would be a useful function for me so why not? \ud83d\ude01</p> <pre><code>function Get-ParentProcess {\n    &lt;#\n    .SYNOPSIS\n    Gets the name and ID of the parent process for the specified process.\n\n    .DESCRIPTION\n    Gets the name and ID of the parent process for the specified process. The\n    process can be specified by object, such as by piping in the results of\n    Get-Process, or by name or ID.\n\n    The output is a [pscustomobject] with the name and ID of the specified\n    process and the parent process if available.\n\n    .PARAMETER InputObject\n    Specifies a Process object such as is returned by the Get-Process cmdlet.\n\n    .PARAMETER Name\n    Specifies one or more process names.\n\n    .PARAMETER Id\n    Specifies one or more process IDs.\n\n    .EXAMPLE\n    Get-ParentProcess notepad\n\n    Gets the parent process for all processes with the name \"notepad\".\n\n    .EXAMPLE\n    Get-ParentProcess -Id 1234\n\n    Gets the parent process for the process with ID 1234.\n\n    .EXAMPLE\n    Get-Process -Name note* | Get-ParentProcess\n\n    Gets the parent process for all processes having a name that starts with \"note\".\n    #&gt;\n    [CmdletBinding(DefaultParameterSetName = 'Name')]\n    [OutputType([pscustomobject])]\n    param(\n        [Parameter(ValueFromPipeline, ParameterSetName = 'InputObject')]\n        [System.Diagnostics.Process[]]\n        $InputObject,\n\n        [Parameter(ValueFromPipelineByPropertyName, ParameterSetName = 'Name', Position = 0)]\n        [string[]]\n        $Name,\n\n        [Parameter(ValueFromPipelineByPropertyName, ParameterSetName = 'Id', Position = 0)]\n        [int[]]\n        $Id\n    )\n\n    process {\n        switch ($PSCmdlet.ParameterSetName) {\n            'InputObject' {\n            }\n\n            'Name' {\n                $InputObject = Get-Process -Name $Name\n            }\n\n            'Id' {\n                $InputObject = Get-Process -Id $Id\n            }\n\n            default {\n                throw \"Parameter set '$_' not implemented.\"\n            }\n        }\n\n        foreach ($process in $InputObject) {\n            $cimProcess = Get-CimInstance -ClassName win32_process -Filter \"ProcessId = $($process.Id)\"\n            $parent = Get-Process -Id $cimProcess.ParentProcessId -ErrorAction SilentlyContinue\n            [pscustomobject]@{\n                Name       = $process.Name\n                Id         = $process.Id\n                ParentName = $parent.Name\n                ParentId   = $parent.Id\n            }\n        }\n    }\n}\n</code></pre> <p>Go ahead and try this function out by copying and pasting it into a PowerShell, terminal then call it using <code>Get-ParentProcess -Id $PID</code>. It should look a bit like this...</p> <pre><code>Get-ParentProcess -Id $PID\n\nName          Id ParentName      ParentId\n----          -- ----------      --------\npowershell 18468 WindowsTerminal    27428\n</code></pre> <p>Now, try typing <code>Get-ParentProcess -Name</code> and press <code>TAB</code>. Chances are PowerShell will fall back to using a file path completer and you'll see something like \".\\something\", which isn't terribly useful. And you'll find the same is true with <code>Get-ParentProcess -Id</code>, even though PowerShell knows that the parameter type for <code>Id</code> is <code>[int]</code>.</p> <p>Wouldn't it be nice if the right values were automatically available to select from? Well, technically since this function accepts processes as pipeline input through the <code>InputObject</code> parameter, you can use <code>Get-Process -Name</code> and then pipe to <code>Get-ParentProcess</code>. But lets make some argument completers anyway!</p>"},{"location":"blog/2022/12/07/your-users-deserve-argument-completers/#argument-completer-for-name","title":"Argument completer for \"Name\"","text":"<p>First I'll introduce the argument completer for the <code>Name</code> parameter. I decided that the completions for this argument should be de-duplicated in case there are multiple matching processes with the same name, and that the completions should be surrounded with single quotes if the name contains any spaces.</p> <pre><code>Register-ArgumentCompleter -CommandName Get-ParentProcess -ParameterName Name -ScriptBlock {\n    param($commandName, $parameterName, $wordToComplete, $commandAst, $fakeBoundParameters)\n\n    # Trim single, or double quotes from the start/end of the word to complete.\n    if ($wordToComplete -match '^[''\"]') {\n        $wordToComplete = $wordToComplete.Trim($Matches.Values[0])\n    }\n\n    # Get all unique process names starting with the characters provided, if any.\n    Get-Process -Name \"$wordToComplete*\" | Select-Object Name -Unique | ForEach-Object {\n        # Wrap the completion in single quotes if it contains any whitespace.\n        if ($_.Name -match '\\s') {\n            \"'{0}'\" -f $_.Name\n        } else {\n            $_.Name\n        }\n    }\n}\n</code></pre> <p>The <code>CommandName</code> and <code>ParameterName</code> parameters and values provided to <code>Register-ArgumentCompleter</code> are self-explanatory but it's worth noting that you can specify multiple command names at once, and even use wildcards. So if you have multiple cmdlets with the same parameter names, and it makes sense to use the same completion for each of them, you only need to register the completer once.</p> <p>The scriptblock begins with a <code>param()</code> declaration with 5 arguments. If you don't include a <code>param()</code> declaration, then those arguments will be available in the <code>$args</code> automatic variable. In this relatively simple use case, we only need the value from <code>$wordToComplete</code>, but here's a quick breakdown of each argument...</p> <code>$commandName</code> <p>The full name of the command for which the completer has been invoked.</p> <code>$parameterName</code> <p>The name of the parameter for which completion is being requested. This may seem strange since you can only specify a single parameter name with <code>Register-ArgumentCompleter</code> but there's nothing stopping you from storing the scriptblock in a variable and re-using it across different commands and even different parameter names. Since the scriptblock will receive the parameter name, you could leverage that to stay \"DRY\" - as in, Don't Repeat Yourself by entering the same, or very similar code many times.</p> <code>$wordToComplete</code> <p>Either an empty string or one or more characters. If there are single or double quotes at the start and/or end of the word, they will be present in the value of this variable.</p> <code>$commandAst</code> <p>This is an \"abstract syntax tree\" which is an abstract representation of the command that the user is preparing to run, including the string content of the entire pipeline. I have not waded into the deep waters of abstract syntax trees yet, but there is great strength in being able to \"look around\" the command being typed by the user. I recommend using the debugger to step into an argument completer scriptblock sometime so you can explore this argument at runtime.</p> <code>$fakeBoundParameters</code> <p>A hashtable where the keys are the other parameters, if any, that the user has specified for the same command. If the values the completer should return might be modified by the presence or value of another parameter, this enables you to augment those results accordingly. For example, if <code>Get-ChildItem -Directory -Path</code> has been typed, it doesn't make sense for PowerShell to suggest any file names. The completions for <code>Path</code> should be exclusively directories. But there's no guarantee that when the user runs the command, any of these \"fake bound parameters\" will still be present.</p> <p>After the <code>param()</code> declaration, a short regular expression is used to check whether <code>$wordToComplete</code> begins with either a single, or a double quote. If it does, then whatever that first character is will be trimmed from both the front and end of the string. That way we don't end up searching for a process named \"'note'pad\" on accident.</p> <p>Finally, we invoke <code>Get-Process</code> with our <code>$wordToComplete</code> with a wildcard character appended on the end to find all processes that start with the characters we have so far. And if the user hasn't supplied any characters, then all processes will be a match. The <code>Select-Object Name -Unique</code> part will select the name from all the results, but only pass the same name to <code>Foreach-Object</code> once. We don't want to return 100 copies of the string \"firefox\" as argument completion suggestions - one is enough.</p> <p>All that is left is to return the matching process name(s), and inside the <code>Foreach-Object</code> scriptblock we take care to wrap the name in single quotes before returning it if the name contains any spaces. If we don't wrap those names in quotes then it will be typed for the user exactly as-is, and result in an error if they don't notice and correct it. It doesn't matter if you wrap strings with single or double quotes in this case - I choose single quotes whenever I know I won't be using string-interpolation like <code>\"Hello $Name\"</code>.</p>"},{"location":"blog/2022/12/07/your-users-deserve-argument-completers/#argument-completer-for-id","title":"Argument completer for \"Id\"","text":"<p>The argument completer for the <code>Id</code> parameter is very similar to the one for the <code>Name</code> parameter. The big difference is that we are expecting the value to be an integer, so we need to do a little validation first. On the up-side, we can simplify how we return the values in the end, because there's no need to wrap the values with quotes.</p> <pre><code>Register-ArgumentCompleter -CommandName Get-ParentProcess -ParameterName Id -ScriptBlock {\n    param($commandName, $parameterName, $wordToComplete, $commandAst, $fakeBoundParameters)\n    $id = $wordToComplete -as [int]\n    if ($null -eq $id) {\n        # The supplied value for Id is not an integer so don't return any completions.\n        return\n    }\n\n    if ([string]::IsNullOrWhiteSpace($wordToComplete)) {\n      $id = $null\n    }\n\n    # Get all processes where the Id starts with the provided number(s), or all processes if no numbers were entered yet.\n    (Get-Process | Where-Object { $_.Id -match \"^$id\" }).Id\n}\n</code></pre> <p>We start by attempting to coerce the string value of <code>$wordToComplete</code> into an integer. If <code>$wordToComplete</code> is null or empty, then the value of <code>$id</code> will be zero. If it is a string like \"100\", then the value of <code>$id</code> will be an integer of that value. And if <code>$wordToComplete</code> has one or more letters or other non-numberic characters, then <code>$id</code> will be null, and we shouldn't return any completions.</p> <p>Now, we either need to get all processes in the event the user hasn't entered any digits yet, or we need to get all processes with a process ID that begins with the digits provided by the user. At this point, if the user hasn't entered any digits, the value of <code>$id</code> is actually \"0\" because a null, or empty string will be cast to an integer as the value \"0\". But we don't want process ID 0 in this case, we want all processes. So before we call <code>Get-Process</code>, we set <code>$id</code> to <code>$null</code> if <code>$wordToComplete</code> is null or whitespace.</p> <p>Finally, we can call Get-process, and then filter the results down with a short regular expression where only the processes with an ID beginning with the value of <code>$id</code> may pass.</p>"},{"location":"blog/2022/12/07/your-users-deserve-argument-completers/#the-final-result","title":"The final result","text":"<p>Here is the full cmdlet with the argument completers. Copy and paste this into your terminal and have a play with the <code>TAB</code> and <code>CTRL+Space</code> list completion. Even better - copy and paste this into VSCode, tinker with the completers, and see how it changes the user experience. Then use the debugger to step into the completer and explore the <code>$commandAst</code> argument to see how you might be able to use it in your projects.</p> <pre><code>function Get-ParentProcess {\n    &lt;#\n    .SYNOPSIS\n    Gets the name and ID of the parent process for the specified process.\n\n    .DESCRIPTION\n    Gets the name and ID of the parent process for the specified process. The\n    process can be specified by object, such as by piping in the results of\n    Get-Process, or by name or ID.\n\n    The output is a [pscustomobject] with the name and ID of the specified\n    process and the parent process if available.\n\n    .PARAMETER InputObject\n    Specifies a Process object such as is returned by the Get-Process cmdlet.\n\n    .PARAMETER Name\n    Specifies one or more process names.\n\n    .PARAMETER Id\n    Specifies one or more process IDs.\n\n    .EXAMPLE\n    Get-ParentProcess notepad\n\n    Gets the parent process for all processes with the name \"notepad\".\n\n    .EXAMPLE\n    Get-ParentProcess -Id 1234\n\n    Gets the parent process for the process with ID 1234.\n\n    .EXAMPLE\n    Get-Process -Name note* | Get-ParentProcess\n\n    Gets the parent process for all processes having a name that starts with \"note\".\n    #&gt;\n    [CmdletBinding(DefaultParameterSetName = 'Name')]\n    [OutputType([pscustomobject])]\n    param(\n        [Parameter(ValueFromPipeline, ParameterSetName = 'InputObject')]\n        [System.Diagnostics.Process[]]\n        $InputObject,\n\n        [Parameter(ValueFromPipelineByPropertyName, ParameterSetName = 'Name', Position = 0)]\n        [string[]]\n        $Name,\n\n        [Parameter(ValueFromPipelineByPropertyName, ParameterSetName = 'Id', Position = 0)]\n        [int[]]\n        $Id\n    )\n\n    process {\n        switch ($PSCmdlet.ParameterSetName) {\n            'InputObject' {\n            }\n\n            'Name' {\n                $InputObject = Get-Process -Name $Name\n            }\n\n            'Id' {\n                $InputObject = Get-Process -Id $Id\n            }\n\n            default {\n                throw \"Parameter set '$_' not implemented.\"\n            }\n        }\n\n        foreach ($process in $InputObject) {\n            $cimProcess = Get-CimInstance -ClassName win32_process -Filter \"ProcessId = $($process.Id)\"\n            $parent = Get-Process -Id $cimProcess.ParentProcessId -ErrorAction SilentlyContinue\n            [pscustomobject]@{\n                Name       = $process.Name\n                Id         = $process.Id\n                ParentName = $parent.Name\n                ParentId   = $parent.Id\n            }\n        }\n    }\n}\n\nRegister-ArgumentCompleter -CommandName Get-ParentProcess -ParameterName Name -ScriptBlock {\n    param($commandName, $parameterName, $wordToComplete, $commandAst, $fakeBoundParameters)\n\n    # Trim single, or double quotes from the start/end of the word to complete.\n    if ($wordToComplete -match '^[''\"]') {\n        $wordToComplete = $wordToComplete.Trim($Matches.Values[0])\n    }\n\n    # Get all unique process names starting with the characters provided, if any.\n    Get-Process -Name \"$wordToComplete*\" | Select-Object Name -Unique | ForEach-Object {\n        # Wrap the completion in single quotes if it contains any whitespace.\n        if ($_.Name -match '\\s') {\n            \"'{0}'\" -f $_.Name\n        } else {\n            $_.Name\n        }\n    }\n}\n\nRegister-ArgumentCompleter -CommandName Get-ParentProcess -ParameterName Id -ScriptBlock {\n    param($commandName, $parameterName, $wordToComplete, $commandAst, $fakeBoundParameters)\n    $id = $wordToComplete -as [int]\n    if ($null -eq $id) {\n        # The supplied value for Id is not an integer so don't return any completions.\n        return\n    }\n\n    if ([string]::IsNullOrWhiteSpace($wordToComplete)) {\n      $id = $null\n    }\n\n    # Get all processes where the Id starts with the provided number(s), or all processes if no numbers were entered yet.\n    (Get-Process | Where-Object { $_.Id -match \"^$id\" }).Id\n}\n</code></pre>"},{"location":"blog/2022/12/21/argument-transformation-attributes/","title":"Argument Transformation Attributes","text":""},{"location":"blog/2022/12/21/argument-transformation-attributes/#introduction","title":"Introduction","text":"<p>Argument transformation attributes make it possible to offer your users some flexibility in how they supply values for parameters. I've started to use these in the MilestonePSTools module to make it possible to provide a name instead of a strongly typed object like a <code>[RecordingServer]</code> or a <code>[Role]</code>, while still making it clear in the <code>Get-Help</code> documentation what the expected object type is, and without polluting functions with object transformation code.</p> <p>In my last post I introduced argument completers, and I consider these an absolute necessity for PowerShell functions and modules that will be shared and used by many people. Argument transformation attributes on the other hand are an advanced feature that can look intimidating to those early in their PowerShell journey. They are, in my opinion, syntactic sugar and thus purely optional.</p>"},{"location":"blog/2022/12/21/argument-transformation-attributes/#example-use-case","title":"Example use case","text":"<p>It has been almost 4 years since the first release of he MilestonePSTools module. In that time, one common question has been about <code>ParameterBindingException</code> errors. For example, if you wanted to get all hardware (cameras) from a recording server, you might try <code>Get-VmsHardware -RecordingServer 'Docker Recorder'</code> which seems perfectly reasonable. But you'd be met with the following error...</p> <pre><code>Cannot bind parameter 'RecordingServer'. Cannot convert the \"Docker Recorder\" value of type \"System.String\" to type \"VideoOS.Platform.ConfigurationItems.RecordingServer\".\n</code></pre> <p></p> <p>The <code>Get-VmsHardware</code> function expects a recording server object instead of a recording server name. The correct usage would then look like...</p> <pre><code>$recorder = Get-VmsRecordingServer -Name 'Docker Recorder'\n\n# Pipe the recording server in to Get-VmsHardware\n$recorder | Get-VmsHardware\n\n# Or provide it as a named parameter\nGet-VmsHardware -RecordingServer $recorder\n</code></pre> <p>By introducing an argument transformation attribute, we can make the <code>Get-VmsHardware</code> function accept either a recording server object, or a recording server name, without changing the parameter type or any of the code within the <code>begin</code>, <code>process</code>, or <code>end</code> blocks.</p>"},{"location":"blog/2022/12/21/argument-transformation-attributes/#writing-an-argument-transformation-attribute","title":"Writing an argument transformation attribute","text":"<p>An argument transformation attribute must be written as a class and inherit from the <code>System.Management.Automation.ArgumentTransformationAttribute</code> class. Your class must then override the <code>Transform(EngineIntrinsics, Object)</code> abstract method which is where the code that performs the object transformation will go.</p> <p>Below you will find my <code>RecorderNameTransformAttribute</code> implementation. I only want it to transform strings into recording server objects. If the value provided by the user is <code>$null</code> or is not a string, then the object will be returned as-is. I could do additional checking during the argument transformation, but PowerShell's own parameter binding and handling of null or invalid types is already so good. Why reinvent the wheel?</p> <pre><code>class RecorderNameTransformAttribute : System.Management.Automation.ArgumentTransformationAttribute {\n\n    ## Override the abstract method \"Transform\". This is where the user\n    ## provided value will be inspected and transformed if possible.\n    [object] Transform([System.Management.Automation.EngineIntrinsics]$engineIntrinsics, [object] $inputData) {\n\n        ## Index recording servers in a hashtable by name so that we can look\n        ## them up by name quickly later, without multiple enumerations.\n        $recorders = @{}\n        Get-VmsRecordingServer | Foreach-Object {\n            $recorders[$_.Name] = $_\n        }\n\n        # $inputData could be a single object or an array, and each element\n        # could be $null, or any other type. The only thing we are interested\n        # in are strings. We'll return everything else unaltered and let\n        # PowerShell throw an error if necessary.\n        return ($inputData | Foreach-Object {\n            $obj = $_\n            if ($obj -is [string]) {\n                if ($recorders.ContainsKey($obj)) {\n                    $obj = $recorders[$obj]\n                } else {\n                    throw [VideoOS.Platform.PathNotFoundMIPException]::new('Recording server \"{0}\" not found.' -f $_)\n                }\n            }\n            $obj\n        })\n    }\n\n    [string] ToString() {\n        return '[RecorderNameTransformAttribute()]'\n    }\n}\n</code></pre>"},{"location":"blog/2022/12/21/argument-transformation-attributes/#using-the-argument-transform-in-get-vmshardware","title":"Using the argument transform in Get-VmsHardware","text":"<p>Once the argument transformation attribute class has been defined, it can be used in any cmdlet or function in your script or module by adding <code>[RecorderNameTransformAttribute()]</code> (or whatever you decide to call your custom attribute) between <code>[Parameter()]</code> and the parameter name. In the definition of <code>Get-VmsHardware</code> below, the highlighted line was the only change required for the function to accept recording servers by name.</p> <pre><code>function Get-VmsHardware {\n    [CmdletBinding(DefaultParameterSetName = 'RecordingServer')]\n    param(\n        [Parameter(ValueFromPipeline, ValueFromPipelineByPropertyName, ParameterSetName = 'RecordingServer')]\n        [RecorderNameTransformAttribute()] # (1)!\n        [ValidateNotNull()]# (2)!\n        [VideoOS.Platform.ConfigurationItems.RecordingServer[]]\n        $RecordingServer,\n\n        [Parameter(Position = 0, Mandatory, ParameterSetName = 'Id')]\n        [Alias('HardwareId')]\n        [guid[]]\n        $Id\n    )\n\n    process {\n        switch ($PSCmdlet.ParameterSetName) {\n            'RecordingServer' {\n                if (-not $MyInvocation.BoundParameters.ContainsKey('RecordingServer')) {\n                    Get-VmsRecordingServer | Get-VmsHardware\n                } else {\n                    $RecordingServer | Foreach-Object {\n                        $_.HardwareFolder.Hardwares\n                    }\n                }\n            }\n\n            'Id' {\n                $serverId = (Get-Site).FQID.ServerId\n                $Id | ForEach-Object {\n                    [VideoOS.Platform.ConfigurationItems.Hardware]::new($serverId, 'Hardware[{0}]' -f $_)\n                }\n            }\n\n            default {\n                throw \"ParameterSetName '$_' not implemented.\"\n            }\n        }\n    }\n}\n</code></pre> <ol> <li>This attribute is the only change required to the <code>Get-VmsHardware</code>    function to enable it to accept recording server names in addition to    <code>[RecordingServer]</code> objects.</li> <li>By adding this attribute we can be sure that all elements in <code>$RecordingServer</code>    have a value and are not <code>$null</code> inside the <code>process {}</code> block.</li> </ol>"},{"location":"blog/2022/12/21/argument-transformation-attributes/#adding-an-argument-completer","title":"Adding an argument completer","text":"<p>While I hold the opinion that argument transformation attributes are nearly always \"extra\" and not required, now that it's been implemented for <code>Get-VmsHardware</code> we should probably make it easy to take advantage of using an argument completer.</p> <p>By adding the argument completer below to the class and function definitions below, the user will be able to tab or list-complete values for the <code>-RecordingServer</code> parameter, making it not only possible to provide a name instead of an object, but easy!</p> <pre><code>Register-ArgumentCompleter -CommandName Get-VmsHardware -ParameterName RecordingServer -ScriptBlock {\n    param($commandName, $parameterName, $wordToComplete, $commandAst, $fakeBoundParameters)\n\n    # Trim single, or double quotes from the start/end of the word to complete.\n    if ($wordToComplete -match '^[''\"]') {\n        $wordToComplete = $wordToComplete.Trim($Matches.Values[0])\n    }\n\n    # Get all unique recorder names starting with the characters provided, if any.\n    $escapedWordToComplete = [System.Text.RegularExpressions.Regex]::Escape($wordToComplete)\n    Get-VmsRecordingServer | Where-Object Name -match \"^$escapedWordToComplete\" | Select-Object Name -Unique | ForEach-Object {\n        # Wrap the completion in single quotes if it contains any whitespace.\n        if ($_.Name -match '\\s') {\n            \"'{0}'\" -f $_.Name\n        } else {\n            $_.Name\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"blog/2022/12/21/argument-transformation-attributes/#the-final-result","title":"The final result","text":"<p>We can now put the three code blocks above together and use it! It's important to note though that when you're working with PowerShell classes like the <code>RecorderNameTransformAttribute</code> class in this example, we can't reference the class before defining the class.</p> <p>What I mean by this is that we can't add the <code>[RecorderNameTransformAttribute()]</code> attribute to a function parameter if the class definition appears somewhere after, or below the <code>Get-VmsHardware</code> function definition. So if you copy &amp; paste the script below as-is, it will work just fine. But if you move the class definition down under the function, PowerShell will complain that it doesn't recognize the <code>RecorderNameTransformAttribute</code> class when it attempts to process the <code>[RecorderNameTransformAttribute()]</code> attribute.</p> <p>When you use classes in a module, it's important to dot source the file(s) where your class(es) are defined before you dot source your functions. And if you have everything in a single .PSM1 file, put your classes at the top of the file so that they are always available when used in your functions.</p> <p>The argument completer on the other hand can be defined anywhere, any time, because PowerShell doesn't attempt to invoke the argument completer script block until you have typed the associated command and parameter.</p> <pre><code>class RecorderNameTransformAttribute : System.Management.Automation.ArgumentTransformationAttribute {\n\n    ## Override the abstract method \"Transform\". This is where the user\n    ## provided value will be inspected and transformed if possible.\n    [object] Transform([System.Management.Automation.EngineIntrinsics]$engineIntrinsics, [object] $inputData) {\n\n        ## Index recording servers in a hashtable by name so that we can look\n        ## them up by name quickly later, without multiple enumerations.\n        $recorders = @{}\n        Get-VmsRecordingServer | Foreach-Object {\n            $recorders[$_.Name] = $_\n        }\n\n        # $inputData could be a single object or an array, and each element\n        # could be $null, or any other type. The only thing we are interested\n        # in are strings. We'll return everything else unaltered and let\n        # PowerShell throw an error if necessary.\n        return ($inputData | Foreach-Object {\n            $obj = $_\n            if ($obj -is [string]) {\n                if ($recorders.ContainsKey($obj)) {\n                    $obj = $recorders[$obj]\n                } else {\n                    throw [VideoOS.Platform.PathNotFoundMIPException]::new('Recording server \"{0}\" not found.' -f $_)\n                }\n            }\n            $obj\n        })\n    }\n\n    [string] ToString() {\n        return '[RecorderNameTransformAttribute()]'\n    }\n}\n\nfunction Get-VmsHardware {\n    [CmdletBinding(DefaultParameterSetName = 'RecordingServer')]\n    param(\n        [Parameter(ValueFromPipeline, ValueFromPipelineByPropertyName, ParameterSetName = 'RecordingServer')]\n        [RecorderNameTransformAttribute()] # (1)!\n        [ValidateNotNull()]# (2)!\n        [VideoOS.Platform.ConfigurationItems.RecordingServer[]]\n        $RecordingServer,\n\n        [Parameter(Position = 0, Mandatory, ParameterSetName = 'Id')]\n        [Alias('HardwareId')]\n        [guid[]]\n        $Id\n    )\n\n    process {\n        switch ($PSCmdlet.ParameterSetName) {\n            'RecordingServer' {\n                if (-not $MyInvocation.BoundParameters.ContainsKey('RecordingServer')) {\n                    Get-VmsRecordingServer | Get-VmsHardware\n                } else {\n                    $RecordingServer | Foreach-Object {\n                        $_.HardwareFolder.Hardwares\n                    }\n                }\n            }\n\n            'Id' {\n                $serverId = (Get-Site).FQID.ServerId\n                $Id | ForEach-Object {\n                    [VideoOS.Platform.ConfigurationItems.Hardware]::new($serverId, 'Hardware[{0}]' -f $_)\n                }\n            }\n\n            default {\n                throw \"ParameterSetName '$_' not implemented.\"\n            }\n        }\n    }\n}\n\nRegister-ArgumentCompleter -CommandName Get-VmsHardware -ParameterName RecordingServer -ScriptBlock {\n    param($commandName, $parameterName, $wordToComplete, $commandAst, $fakeBoundParameters)\n\n    # Trim single, or double quotes from the start/end of the word to complete.\n    if ($wordToComplete -match '^[''\"]') {\n        $wordToComplete = $wordToComplete.Trim($Matches.Values[0])\n    }\n\n    # Get all unique recorder names starting with the characters provided, if any.\n    $escapedWordToComplete = [System.Text.RegularExpressions.Regex]::Escape($wordToComplete)\n    Get-VmsRecordingServer | Where-Object Name -match \"^$escapedWordToComplete\" | Select-Object Name -Unique | ForEach-Object {\n        # Wrap the completion in single quotes if it contains any whitespace.\n        if ($_.Name -match '\\s') {\n            \"'{0}'\" -f $_.Name\n        } else {\n            $_.Name\n        }\n    }\n}\n</code></pre> <ol> <li>This attribute is the only change required to the <code>Get-VmsHardware</code>    function to enable it to accept recording server names in addition to    <code>[RecordingServer]</code> objects.</li> <li>By adding this attribute we can be sure that all elements in <code>$RecordingServer</code>    have a value and are not <code>$null</code> inside the <code>process {}</code> block.</li> </ol>"},{"location":"blog/2023/10/02/generate-markdown-tables-from-powershell/","title":"Generate markdown tables from PowerShell","text":"<p>I had a need to generate a markdown table dynamically from PowerShell, so I wrote a flexible function which uses the properties on the incoming objects to define the column names, supports the definition of maximum column widths, and outputs either pretty-printed markdown with padded values and aligned columns, or \"compressed\" markdown without the unnecessary padding included.</p> <p>As an alternative when working an mkdocs project, you can use the table-reader plugin to reference a CSV file in markdown. I tested this out successfully and it's a really handy tool, but in the end I wanted a method of generating a markdown table that did not depend on the use of mkdocs or python.</p> <p>Download </p> <pre><code>function ConvertTo-MarkdownTable {\n    &lt;#\n    .SYNOPSIS\n    Converts a collection of objects into a markdown-formatted table.\n\n    .DESCRIPTION\n    The `ConvertTo-MarkdownTable` function converts a collection of objects into a markdown-formatted table. The names\n    of all properties on the first object are used as column names in the order they are defined. If subsequent objects\n    define properties that were not present on the first item processed, those additional properties will be ignored\n    and columns will not be created for them.\n\n    Optionally, a maximum width can be specified for one, or all columns using MaxColumnWidth. However, if the length\n    of the name column header is greater than the specified MaxColumnWidth, the MaxColumnWidth value used for that\n    column will be the length of the column header. Rows with column values longer than MaxColumnWidth will be truncated\n    and the Ellipsis string will be appended to the end with the length of the resulting string, plus ellipsis characters,\n    equaling the MaxColumnWidth value for that column.\n\n    By default, all columns will be padded with a space between any column header or value and the \"|\" characters on\n    either side. Values shorter than the longest value in the column will be right-padded so that all \"|\" characters\n    align vertically throughout the table.\n\n    If the additional white space is not desired, use of the `Compress` switch will omit any unnecessary white space.\n\n    .PARAMETER InputObject\n    Specified the object, or a collection of objects to represent in the resulting markdown data table. All properties\n    of InputObject will be used to define the resulting columns. Consider using `Select-Object` first to select which\n    properties on the source object should be passed to this function.\n\n    .PARAMETER MaxColumnWidth\n    Specifies the maximum length of all columns if one value is provided, or the maximum length of each individual column\n    if more than one value is provided. When providing more than one value, you must provide a value for every column. Columns\n    with values longer than MaxColumnWidth will be truncated, and the Ellipsis characters will be appended. The length\n    of the resulting string with ellipsis will match the MaxColumnWidth value.\n\n    The default value is `[int]::MaxValue` so effectively no columns will be truncated. And the minimum value is the length\n    of Ellipsis + 1, or 4 by default.\n\n    .PARAMETER Ellipsis\n    Specifies the characters to use as an ellipsis. By default, the ellipsis value is \"...\", but this can be overridden\n    to be an empty string, or some other value. The minimum value for MaxColumnWidth is defined as 1 + the length of Ellipsis.\n\n    .PARAMETER Compress\n    Specifies that no extra padding should be added to make the \"|\" symbols align vertically.\n\n    .EXAMPLE\n    Get-Process | Select-Object Name, Id, VirtualMemorySize | ConvertTo-MarkdownTable -MaxColumnWidth 16\n\n    Gets a list of processes, selects the Name, Id, and VirtualMemorySize properties, and returns a markdown-formatted\n    table representing all properties with a maximum column width of 16 characters.\n\n    .EXAMPLE\n    Get-Service | Select-Object DisplayName, Name, Status | ConvertTo-MarkdownTable\n\n    Generates a markdown-formatted table with the DisplayName, Name, and Status properties of all services.\n\n    .EXAMPLE\n    Get-Service | Select-Object DisplayName, Name, Status | ConvertTo-MarkdownTable -Compress\n\n    Generates a markdown-formatted table with the DisplayName, Name, and Status properties of all services, without any\n    unnecessary padding, resulting in a much shorter string for large sets of data.\n    #&gt;#\n    [CmdletBinding()]\n    [OutputType([string])]\n    param(\n        [Parameter(Mandatory, ValueFromPipeline, Position = 0)]\n        [psobject[]]\n        $InputObject,\n\n        [Parameter()]\n        [ValidateRange(1, [int]::MaxValue)]\n        [int[]]\n        $MaxColumnWidth = ([int]::MaxValue),\n\n        [Parameter()]\n        [string]\n        $Ellipsis = '...',\n\n        [Parameter()]\n        [switch]\n        $Compress\n    )\n\n    begin {\n        $MaxColumnWidth | ForEach-Object {\n            if ($_ -le $Ellipsis.Length) {\n                throw \"MaxColumnWidth values must be greater than $($Ellipsis.Length) which is the length of the Ellipsis parameter. $_\"\n            }\n        }\n        $items = [system.collections.generic.list[object]]::new()\n        $columns = [ordered]@{}\n        $firstRecordProcessed = $false\n    }\n\n    process {\n        foreach ($item in $InputObject) {\n            $items.Add($item)\n            $columnNumber = 0\n            foreach ($property in $item.PSObject.Properties) {\n                if ($MaxColumnWidth.Count -gt 1 -and $MaxColumnWidth.Count -lt ($columnNumber + 1)) {\n                    throw \"No MaxColumnWidth value defined for column $($columnNumber + 1). MaxColumnWidth must define a single value for all columns, or one value for each column.\"\n                }\n\n                $maxLength = $MaxColumnWidth[0]\n                if ($MaxColumnWidth.Count -gt 1) {\n                    $maxLength = $MaxColumnWidth[$columnNumber]\n                }\n\n                if (-not $columns.Contains($property.Name)) {\n                    if ($firstRecordProcessed) {\n                        Write-Warning \"Ignoring property '$($property.Name)' on $item because the property was not present in the first item processed.\"\n                        continue\n                    } else {\n                        $columns[$property.Name] = $property.Name.Length\n                        if ($property.Name.Length -gt $maxLength) {\n                            $maxLength = $property.Name.Length\n                            Write-Warning \"The header for column $columnNumber, '$($property.Name)', is longer than the MaxColumnWidth value provided. The MaxColumnWidth value for this column is now $maxLength.\"\n                        }\n                    }\n                }\n\n                $length = 0\n                if ($null -ne $property.Value) {\n                    $length = [math]::Min($maxLength, $property.Value.ToString().Length)\n                }\n\n                if ($columns[$property.Name] -lt $length) {\n                    $columns[$property.Name] = $length\n                }\n                $columnNumber++\n            }\n            $firstRecordProcessed = $true\n        }\n    }\n\n    end {\n        function Shorten {\n            param(\n                [Parameter(ValueFromPipeline)]\n                [string]\n                $InputObject,\n\n                [Parameter(Mandatory)]\n                [ValidateRange(1, [int]::MaxValue)]\n                [int]\n                $MaxLength,\n\n                [Parameter()]\n                [string]\n                $Ellipsis = '...'\n            )\n\n            process {\n                if ($InputObject.Length -gt $MaxLength) {\n                    '{0}{1}' -f $InputObject.Substring(0, ($MaxLength - $Ellipsis.Length)), $Ellipsis\n                } else {\n                    $InputObject\n                }\n            }\n        }\n\n        $sb = [text.stringbuilder]::new()\n\n        # Header\n        $paddedColumnNames = $columns.GetEnumerator() | ForEach-Object {\n            $text = $_.Key | Shorten -MaxLength $_.Value -Ellipsis $Ellipsis\n            if ($Compress) {\n                ' {0} ' -f $text\n            } else {\n                ' {0} ' -f ($text.PadRight($_.Value))\n            }\n        }\n        $null = $sb.AppendLine('|' + ($paddedColumnNames -join '|') + '|')\n        $null = $sb.AppendLine('|' + (($paddedColumnNames | ForEach-Object { '-' * $_.Length } ) -join '|') + '|')\n\n        foreach ($item in $items) {\n            $paddedRowValues = $columns.GetEnumerator() | ForEach-Object {\n                $text = [string]::Empty\n                if ($null -ne $item.($_.Key)) {\n                    $text = $item.($_.Key) | Shorten -MaxLength $_.Value -Ellipsis $Ellipsis\n                }\n                if ($Compress) {\n                    ' {0} ' -f $text\n                } else {\n                    ' {0} ' -f $text.PadRight($_.Value)\n                }\n            }\n\n            $null = $sb.AppendLine('|' + ($paddedRowValues -join '|') + '|')\n        }\n        $sb.ToString()\n    }\n}\n</code></pre>"},{"location":"blog/2023/10/12/parse-code-from-markdown-files/","title":"Parse Code from Markdown Files","text":""},{"location":"blog/2023/10/12/parse-code-from-markdown-files/#introduction","title":"Introduction","text":"<p>Are you testing your documentation? If you write PowerShell scripts or modules, you are hopefully using Pester to test your code. And if you use PlatyPS to generate markdown documentation like I do, then you have a bunch of example PowerShell code sitting in .md files. But what happens if you rename a command, a parameter, or make a breaking change?</p> <p>Your documentation is the face of your product. It's the source of truth for the people who use it, whether it's a PowerShell module or something else entirely unrelated. When your examples have errors in them, it won't be obvious to everyone. Some people may copy and paste your examples, see an error, and move on. Maybe they see the use of aliases and other coding patterns that are generally not recommended to use in source code or documentation and pick up those habits, or they become unsure about the overall quality of the product behind the documentation?</p> <p>The MilestonePSTools PowerShell module I work on has 413 markdown files under the docs folder, and 394 of those files were generated by PlatyPS for commands in the module (in English and Spanish). I have a bunch of tests for the module itself, but until today I was not testing any examples or other PowerShell code blocks found in the documentation.</p>"},{"location":"blog/2023/10/12/parse-code-from-markdown-files/#oh-aliases","title":"Oh aliases...","text":"<p>My PowerShell journey started in 2019 when I began building a module. I was learning PowerShell at the same time I was building what would become a commercially used module, and learning best practices and common patterns from the community. One important best practice I failed to learn early on was use a prefix for the nouns in command names to prevent collisions with commands from other modules. So after I while, I started to add a \"Vms\" prefix to the commands in the module, and I started renaming commands and adding an alias to the new command matching the old one to help prevent breaking changes.</p> <p>The Pester test screenshot at the top of this post shows that there are some old pre-prefix commands still in use. At the time the documentation was written, these weren't aliases at all. But they are now, and people reading this documentation might be confused about the command names, or they may just naturally start using the alias version of those commands because it's in the documentation so it must be right!</p> <p></p>"},{"location":"blog/2023/10/12/parse-code-from-markdown-files/#demonstration","title":"Demonstration","text":"<p>Let's take a look at an excerpt of the docs from another command, this time in markdown format. In the first example for <code>Update-Bookmark</code>, I used the \"%\" alias in place of <code>ForEach-Object</code>. To be fair, I wanted to keep the example line from being too long. But I know there are better strategies to achieve that.</p> Update-Bookmark.md<pre><code># Update-Bookmark\n\n## SYNOPSIS\n\nUpdates the properties of a bookmark\n\n## SYNTAX\n\n```\nUpdate-Bookmark -Bookmark &lt;Bookmark&gt; [&lt;CommonParameters&gt;]\n```\n\n## DESCRIPTION\n\nThe `Update-Bookmark` command updates a bookmark in the VMS by pushing changes\nto the bookmark object up to the Management Server.\n\nThe expected workflow is that a bookmark is retrieved using Get-Bookmark.\nThen properties of the local bookmark object are changed as desired.\nFinally the modified local bookmark object is used to update the record on the Management Server by piping it to this cmdlet.\n\nREQUIREMENTS\n\n- Requires VMS connection and will attempt to connect automatically\n\n## EXAMPLES\n\n### EXAMPLE 1\n\n```powershell\nGet-Bookmark -Timestamp '2019-06-04 14:00:00' -Minutes 120 | % { $_.Description = 'Testing'; $_ | Update-Bookmark }\n```\n\nGets all bookmarks for any device where the bookmark time is between 2PM and 4PM local time on the 4th of June, changes the Description to 'Testing', and sends the updated bookmark to the Management Server.\n</code></pre> <p>The <code>Get-MdCodeBlock</code> command uses regular expressions to determine whether a line represents the beginning, or end of a code fence, and whether inline code is present in that line. If a language shortcode is used, that information is grabbed and returned with each code block. For the markdown example above, that looks like...</p> <pre><code>Get-MdCodeBlock -Path .\\Update-Bookmark.md | Select-Object Source, LineNumber, Position, Inline, Language | Format-Table\n\n# Source                  LineNumber Position Inline Language\n# ------                  ---------- -------- ------ --------\n# Update-Bookmark.md               9        0  False\n# Update-Bookmark.md              15        4   True\n# Update-Bookmark.md              30        0  False powershell\n</code></pre> <p>For brevity I didn't include the <code>Content</code> property in the example output above, but you can probably see the value in checking all of the example code you wrote years ago and never looked at again, despite the code base seeing dramatic changes and growth over time.</p>"},{"location":"blog/2023/10/12/parse-code-from-markdown-files/#sample-pester-test","title":"Sample Pester Test","text":"<p>Here's a basic Pester test which uses <code>Get-MdCodeBlock</code> to extract the powershell example and pass the content to <code>Invoke-ScriptAnalyzer</code>.</p> markdown.tests.ps1<pre><code>Describe 'Markdown Tests' {\n    Context 'PowerShell Code Blocks are Valid' {\n        BeforeDiscovery {\n            . $PSScriptRoot\\Get-MdCodeBlock.ps1\n            $script:codeBlocks = Get-ChildItem '*.md' | Get-MDCodeBlock -Language powershell\n        }\n\n        It 'Analyze codeblock at &lt;_&gt;' -ForEach $script:codeBlocks {\n            $analysis = Invoke-ScriptAnalyzer -ScriptDefinition $_.Content -Settings PSGallery\n            $analysis | Where-Object Severity -ge 'Warning' | Out-String | Should -BeNullOrEmpty\n        }\n    }\n}\n</code></pre> <p>I absolutely love having this improved visibility into the health of the documentation. The tests call out the file, line number, and give me the formatted output from PSScriptAnalyzer. And you can get even more creative by using the PowerShell language parser to extract an abstract syntax tree and inspect all code hiding in markdown files for just about anything.</p> <p></p>"},{"location":"blog/2023/10/12/parse-code-from-markdown-files/#code","title":"Code","text":"<p>Download </p> <pre><code>using namespace System.Text\nusing namespace System.Text.RegularExpressions\n\nenum MdState {\n    Undefined\n    InCodeBlock\n}\n\nclass CodeBlock {\n    [string] $Source\n    [string] $Language\n    [string] $Content\n    [int]    $LineNumber\n    [int]    $Position\n    [bool]   $Inline\n\n    [string] ToString() {\n        return '{0}:{1}:{2}' -f $this.Source, $this.LineNumber, $this.Language\n    }\n}\n\nfunction Get-MdCodeBlock {\n    &lt;#\n    .SYNOPSIS\n    Gets code from inline code and fenced code blocks in markdown files.\n\n    .DESCRIPTION\n    Gets code from inline code and fenced code blocks in markdown files with\n    support for simple PyMdown Snippets syntax, and the PyMdown InlineHilite\n    extension which allows you to use a \"shebang\" like `#!powershell Get-ChildItem *.md -Recurse | Get-MdCodeBlock`.\n\n    .PARAMETER Path\n    Specifies the path to the markdown file from which to extract code blocks.\n\n    .PARAMETER BasePath\n    Specifies the base path to use when resolving relative file paths for the CodeBlock object's Source property.\n\n    .PARAMETER Language\n    Specifies that only the codeblocks with the named language shortcode should be returned.\n\n    .EXAMPLE\n    Get-ChildItem -Path .\\*.md -Recurse | Get-MdCodeBlock\n\n    Gets information about inline and fenced code from all .md files in the current directory and any subdirectories\n    recursively.\n\n    .EXAMPLE\n    Get-MdCodeBlock -Path docs\\*.md -BasePath docs\\\n\n    Gets information about inline and fenced code from all .md files in the \"docs\" subdirectory. The Source property\n    on each CodeBlock object returned will be relative to the docs subdirectory.\n\n    .EXAMPLE\n    Get-MDCodeBlock -Path docs\\*.md -BasePath docs\\ -Language powershell | ForEach-Object {\n        Invoke-ScriptAnalyzer -ScriptDefinition $_.Content\n    }\n\n    Gets all inline and fenced PowerShell code from all .md files in the docs\\ directory, and runs each of them through\n    PSScriptAnalyzer using `Invoke-ScriptAnalyzer`.\n\n    .EXAMPLE\n    Get-ChildItem -Path *.md -Recurse | Get-MdCodeBlock | Where-Object Language -eq 'powershell' | ForEach-Object {\n        $tokens = $errors = $null\n        $ast = [management.automation.language.parser]::ParseInput($_.Content, [ref]$tokens, [ref]$errors)\n        [pscustomobject]@{\n            CodeBlock = $_\n            Tokens    = $tokens\n            Errors    = $errors\n            Ast       = $ast\n        }\n    }\n\n    Gets all inline and fenced powershell code from all markdown files in the current directory and all subdirectories,\n    and runs them through the PowerShell language parser to return a PSCustomObject with the original CodeBlock, and the\n    tokens, errors, and Abstract Syntax Tree returned by the language parser. You might use this to locate errors in\n    your documentation, or find very specific elements of PowerShell code.\n\n    .NOTES\n    [Pymdown Snippets extension](https://facelessuser.github.io/pymdown-extensions/extensions/snippets/)\n    [Pymdown InlineHilite extension](https://facelessuser.github.io/pymdown-extensions/extensions/inlinehilite/)\n    #&gt;\n    [CmdletBinding()]\n    [OutputType([CodeBlock])]\n    param (\n        [Parameter(Mandatory, ValueFromPipeline, Position = 0)]\n        [string[]]\n        [SupportsWildcards()]\n        $Path,\n\n        [Parameter()]\n        [string]\n        $BasePath = '.',\n\n        [Parameter()]\n        [string]\n        $Language\n    )\n\n    process {\n        foreach ($unresolved in $Path) {\n            foreach ($file in (Resolve-Path -Path $unresolved).Path) {\n                $file = (Resolve-Path -Path $file).Path\n                $BasePath = (Resolve-Path -Path $BasePath).Path\n                $escapedRoot = [regex]::Escape($BasePath)\n                $relativePath = $file -replace \"$escapedRoot\\\\\", ''\n\n\n                # This section imports files referenced by PyMdown snippet syntax\n                # Example: --8&lt;-- \"abbreviations.md\"\n                # Note: This function only supports very basic snippet syntax.\n                # See https://facelessuser.github.io/pymdown-extensions/extensions/snippets/ for documentation on the Snippets PyMdown extension\n                $lines = [io.file]::ReadAllLines($file, [encoding]::UTF8) | ForEach-Object {\n                    if ($_ -match '--8&lt;-- \"(?&lt;file&gt;[^\"]+)\"') {\n                        $snippetPath = Join-Path -Path $BasePath -ChildPath $Matches.file\n                        if (Test-Path -Path $snippetPath) {\n                            Get-Content -Path $snippetPath\n                        } else {\n                            Write-Warning \"Snippet not found: $snippetPath\"\n                        }\n                    } else {\n                        $_\n                    }\n                }\n\n\n                $lineNumber = 0\n                $code = $null\n                $state = [MdState]::Undefined\n                $content = [stringbuilder]::new()\n\n                foreach ($line in $lines) {\n                    $lineNumber++\n                    switch ($state) {\n                        'Undefined' {\n                            if ($line -match '^\\s*```(?&lt;lang&gt;\\w+)?' -and ([string]::IsNullOrWhiteSpace($Language) -or $Matches.lang -eq $Language)) {\n                                $state = [MdState]::InCodeBlock\n                                $code = [CodeBlock]@{\n                                    Source     = $relativePath\n                                    Language   = $Matches.lang\n                                    LineNumber = $lineNumber\n                                }\n                            } elseif (($inlineMatches = [regex]::Matches($line, '(?&lt;!`)`(#!(?&lt;lang&gt;\\w+) )?(?&lt;code&gt;[^`]+)`(?!`)'))) {\n                                if (-not [string]::IsNullOrWhiteSpace($Language) -and $inlineMatch.Groups.lang -ne $Language) {\n                                    continue\n                                }\n                                foreach ($inlineMatch in $inlineMatches) {\n                                    [CodeBlock]@{\n                                        Source     = $relativePath\n                                        Language   = $inlineMatch.Groups.lang\n                                        Content    = $inlineMatch.Groups.code\n                                        LineNumber = $lineNumber\n                                        Position   = $inlineMatch.Index\n                                        Inline     = $true\n                                    }\n                                }\n                            }\n                        }\n\n                        'InCodeBlock' {\n                            if ($line -match '^\\s*```') {\n                                $state = [MdState]::Undefined\n                                $code.Content = $content.ToString()\n                                $code\n                                $code = $null\n                                $null = $content.Clear()\n                            } else {\n                                $null = $content.AppendLine($line)\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"blog/2022/01/04/securely-reading-passwords-from-the-console/","title":"Securely Reading Passwords from the Console","text":"<p>If you've ever written a console application which requires the user to enter sensitive information like a password or a token, you might have wrestled with concerns of exposing the password in plain text within the console window.</p> <p>I was writing a new console application earlier today after spending most of my time in PowerShell for the last three years, and I found myself wanting to use <code>Read-Host -AsSecureString</code>, and remembered how much I take for granted that PowerShell gives us so much for free.</p> <p>After making sure none of the <code>Console.Read*</code> methods baked into .NET would give me what I wanted, I wrote a fairly short <code>SecureConsole</code> class with a <code>SecureConsole.ReadLine()</code> method along with a <code>SecureConsole.GetCredential(string message)</code> method. I wanted to emulate PowerShell's <code>Get-Credential</code> since I needed both a username and password.</p> <p>Here's what I ended up with. The <code>SecureConsole.ReadLine()</code> method will...</p> <ol> <li>read any non-control character entered by the user</li> <li>append each new <code>char</code> to a <code>System.Security.SecureString</code></li> <li>write an asterisk (*) symbol back to the console</li> <li>accept the backspace key and behave as expected</li> </ol> <p></p> <p>Here's the <code>SecureConsole</code> class, and a demo program where I'm calling <code>SecureConsole.GetCredential()</code> to prompt the user for their credentials. The password will be recorded as a <code>SecureString</code> and then paired with the username to create a <code>System.Net.NetworkCredential</code>. For testing purposes, the plain text password from the credential is printed out to verify the text was received properly. Read on after the code sample for details.</p> program.cs<pre><code>using System;\nusing System.Net;\nusing System.Security;\n\nnamespace SecureConsoleDemo\n{\n  internal class Program\n  {\n    static void Main(string[] args)\n    {\n      while (true)\n      {\n        Console.Clear();\n        var nc = SecureConsole.GetCredential();\n        if (nc.UserName == String.Empty)\n        {\n          break;\n        }\n\n        // For testing purposes, your securestring password will be\n        // revealed in plain text to verify it was accurately read\n        // and control characters properly ignored.\n        Console.WriteLine($\"You entered '{nc.Password}'\");\n        Console.WriteLine(\"Press any key to continue. . .\");\n        Console.ReadKey(true);\n      }\n    }\n  }\n\n  public static class SecureConsole\n  {\n    public static NetworkCredential GetCredential()\n    {\n      return GetCredential(string.Empty);\n    }\n\n    public static NetworkCredential GetCredential(string message)\n    {\n      if (!string.IsNullOrWhiteSpace(message))\n      {\n        Console.WriteLine(message);\n      }\n      Console.Write(\"Username: \");\n      var username = Console.ReadLine();\n\n      Console.Write(\"Password: \");\n      var password = SecureConsole.ReadLine();\n\n      return new NetworkCredential(username, password);\n    }\n\n    public static SecureString ReadLine()\n    {\n      var password = new SecureString();\n      ConsoleKeyInfo key;\n      while ((key = Console.ReadKey(true)).Key != ConsoleKey.Enter)\n      {\n        if (key.Key == ConsoleKey.Backspace &amp;&amp; password.Length &gt; 0)\n        {\n          Console.Write(\"\\b \\b\");\n          password.RemoveAt(password.Length - 1);\n        }\n        else if (!char.IsControl(key.KeyChar))\n        {\n          Console.Write(\"*\");\n          password.AppendChar(key.KeyChar);\n        }\n      }\n      Console.Write(Environment.NewLine);\n      return password;\n    }\n  }\n}\n</code></pre>"},{"location":"blog/2022/01/04/securely-reading-passwords-from-the-console/#the-main-loop","title":"The main loop","text":"<p>The program is a simple loop where we read from the console until the user enters a credential with a blank user name. Once a credential is entered, the password is printed to the screen and we do it again.</p> program.cs<pre><code>    static void Main(string[] args)\n    {\n      while (true) // (1)\n      {\n        Console.Clear();\n        var nc = SecureConsole.GetCredential(); // (2)\n        if (nc.UserName == String.Empty)\n        {\n          break;\n        }\n\n        // For testing purposes, your securestring password will be\n        // revealed in plain text to verify it was accurately read\n        // and control characters properly ignored.\n        Console.WriteLine($\"You entered '{nc.Password}'\"); // (3)\n        Console.WriteLine(\"Press any key to continue. . .\");\n        Console.ReadKey(true); // (4)\n      }\n    }\n</code></pre> <ol> <li>This loop will continue forever, or until we reach the <code>break;</code> on line 17 by pressing enter without entering a username.</li> <li>The <code>GetCredential()</code> method is called here without a message, and it returns a <code>System.Net.NetworkCredential</code> object.</li> <li>This is a just a sample, and for testing purposes we print the <code>Password</code> property of the network credential we received. This statement uses string interpolation.</li> <li>We call <code>Console.ReadKey()</code> with the boolean <code>true</code> to indicate that the key should be suppressed from the console.</li> </ol>"},{"location":"blog/2022/01/04/securely-reading-passwords-from-the-console/#the-getcredential-methods","title":"The GetCredential() methods","text":"<p>At the top of the <code>SecureConsole</code> class are the <code>GetCredential()</code> and an overload <code>GetCredential(message)</code> which optionally prints the specified message to the user before presenting the \"Username\" and \"Password\" fields.</p> program.cs<pre><code>  public static class SecureConsole\n  {\n    public static NetworkCredential GetCredential()\n    {\n      return GetCredential(string.Empty); // (1)\n    }\n\n    public static NetworkCredential GetCredential(string message)\n    {\n      if (!string.IsNullOrWhiteSpace(message)) // (2)\n      {\n        Console.WriteLine(message);\n      }\n      Console.Write(\"Username: \");\n      var username = Console.ReadLine();\n\n      Console.Write(\"Password: \");\n      var password = SecureConsole.ReadLine(); // (3)\n\n      return new NetworkCredential(username, password);\n    }\n</code></pre> <ol> <li>In the first overload of the <code>GetCredential()</code> method, we call the second overload with an empty message.</li> <li>In the second overload of <code>GetCredential()</code>, we print the message to the console if one was provided.</li> <li>Then we collect the plain text username and a <code>System.Security.SecureString</code> password before returning the pair in a new <code>System.Net.NetworkCredential</code>.</li> </ol>"},{"location":"blog/2022/01/04/securely-reading-passwords-from-the-console/#secureconsolereadline","title":"SecureConsole.ReadLine()","text":"<p>Finally, the <code>SecureConsole.ReadLine()</code> method. It's similar to <code>Console.ReadLine()</code> in behavior as accepts console input until a carriage return is received. The difference is that the character will not be written to the terminal, it gets stored one character at a time into an encrypted <code>SecureString</code>, and an asterisk will be written to the console so the user recognizes that the character has been received.</p> program.cs<pre><code>public static SecureString ReadLine()\n    {\n      var password = new SecureString();\n      ConsoleKeyInfo key;\n      while ((key = Console.ReadKey(true)).Key != ConsoleKey.Enter) // (1)\n      {\n        if (key.Key == ConsoleKey.Backspace &amp;&amp; password.Length &gt; 0) // (2)\n        {\n          Console.Write(\"\\b \\b\");\n          password.RemoveAt(password.Length - 1);\n        }\n        else if (!char.IsControl(key.KeyChar)) // (3)\n        {\n          Console.Write(\"*\");\n          password.AppendChar(key.KeyChar);\n        }\n      }\n      Console.Write(Environment.NewLine); // (4)\n      return password;\n    }\n  }\n}\n</code></pre> <ol> <li>This <code>while</code> loop uses <code>Console.ReadKey(true)</code> to receive a keypress from the console, and as long as it isn't an Enter key, the loop executes.</li> <li>Next we check to see if the key was the <code>ConsoleKey.Backspace</code>. If so, we write two <code>\\b</code> backspace characters to the terminal on either side of a \"space\" character. This effectively types \"backspace - space - backspace\" into the console to erase the last asterisk.</li> <li>If the key wasn't a backspace, and the key is also not a control character like CTRL or HOME, then an asterisk is written to the console, and we append the character to the SecureString defined on line 54.</li> <li>We're now out of the <code>while</code> loop, but the last Enter keypress was suppressed from the console, so we use <code>Console.Write(Environment.NewLine)</code> to move the console cursor to the start of the next line before returning the completed <code>SecureString</code>.</li> </ol>"},{"location":"blog/2022/01/04/securely-reading-passwords-from-the-console/#final-thoughts","title":"Final thoughts","text":"<p>There are probably more secure and complex ways to protect user input in a console app and thwart shoulder-surfing ne'er-do-wells, but this method seemed like a solid, lightweight alternative to showing passwords in plain text and storing them in simple strings. I wonder if there's a way to do it where we don't keep an unprotected <code>char</code> in memory? Let me know if there's a simpler, and/or more secure method to accomplish the same thing within the scope of a console application!</p>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/category/powershell/","title":"PowerShell","text":""},{"location":"blog/category/homelab/","title":"Homelab","text":""},{"location":"blog/category/mkdocs/","title":"MkDocs","text":""},{"location":"blog/category/windows/","title":"Windows","text":""},{"location":"blog/category/computer-vision/","title":"Computer Vision","text":""},{"location":"blog/category/documentation/","title":"Documentation","text":""},{"location":"blog/category/github-actions/","title":"GitHub Actions","text":""},{"location":"blog/category/cicd/","title":"CI/CD","text":""},{"location":"blog/category/markdown/","title":"Markdown","text":""},{"location":"blog/category/usability/","title":"Usability","text":""},{"location":"blog/category/c/","title":"C#","text":""}]}